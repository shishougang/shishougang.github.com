<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: Multithreading | (learn&think)]]></title>
  <link href="http://dreamrunner.org/tags/multithreading/atom.xml" rel="self"/>
  <link href="http://dreamrunner.org/"/>
  <updated>2014-06-28T23:22:43+08:00</updated>
  <id>http://dreamrunner.org/</id>
  <author>
    <name><![CDATA[DreamRunner]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[浅谈Memory Reordering]]></title>
    <link href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/"/>
    <updated>2014-06-28T22:55:22+08:00</updated>
    <id>http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering</id>
    <content type="html"><![CDATA[<h2 id="memory-ordering">Memory ordering</h2>
<p>在我们编写的C/C++代码和它被在CPU上运行,按照一些规则,代码的内存交互会被
乱序.内存乱序同时由编译器(编译时候)和处理器(运行时)造成,都为了使代码运
行的更快.</p>

<p><img src="/images/blog/2014/multithreading/memory_model.png" title="‘memory_ordering’" ></p>

<p>被编译开发者和处理器制造商遵循的中心内存排序准则是:
<blockquote><p>不能改变单线程程序的行为.</p></blockquote></p>

<p>因为这条规则,在写单线程代码时内存乱序被普遍忽略.即使在多线程程序中,它
也被时常忽略,因为有mutexes,semaphores等来防止它们调用中的内存乱序.仅当
lock-free技术被使用时,内存在不受任何互斥保护下被多个线程共享,内存乱序
的影响能被看到.</p>

<p>下面先比较Weak和Strong的内存模型,然后分两部分,实际内存乱序如何在编译和运行时发生,并如何防止它们.</p>

<!-- more -->

<h2 id="weak-vs-strong-memory-models">Weak VS strong Memory Models</h2>
<p><a href="http://preshing.com/about">Jeff Preshing</a>在
<a href="http://preshing.com/20120930/weak-vs-strong-memory-models/">Weak vs. Strong Memory Models</a>
中很好的总结了从Weak到Strong的类型:</p>

<table>
  <thead>
    <tr>
      <th>非常弱</th>
      <th>数据依赖性的弱</th>
      <th>强制</th>
      <th>顺序一致</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>DEC Alpha</td>
      <td>ARM</td>
      <td>X86/64</td>
      <td>dual 386</td>
    </tr>
    <tr>
      <td>C/C++11 low-level atomics</td>
      <td>PowerPC</td>
      <td>SPARC TSO</td>
      <td>Java volatile/C/C++11 atomics</td>
    </tr>
  </tbody>
</table>

<h3 id="section">弱内存模型</h3>

<p>在最弱的内存模型中,可能经历所有四种内存乱序
(<a href="http://g.oswego.edu/dl/jmm/cookbook.html">LoadLoad, StoreStore, LoadStore and StoreLoad</a>).任
何load或store的操作能与任何的其他的load或store操作乱序,只要它不改变一
个独立进程的行为.实际中,这样的乱序由于编译器引起的指令乱序或处理器本身
处理指令的乱序.</p>

<p>当处理器是弱硬件内存模式,通常称它为weakly-ordered或weak ordering.或说
它有relaxed memory model. <strong>DEC Alpha</strong> 是
<a href="http://www.mjmwired.net/kernel/Documentation/memory-barriers.txt#2277">最具代表</a>
的弱排序的处理器.</p>

<p>C/C++的底层原子操作也呈现弱内存模型,无论代码的平台是如x86/64的强序处理
器.下面章节
<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/#memory-ordering-at-compile-time">Memory ordering at compile time</a>
会演示其弱内存模型,并说明如何强制内存顺
序来保护编译器乱序.</p>

<h3 id="section-1">数据依赖性的弱</h3>

<p>ARM和PowerPC系列的处理器内存模型和Alpha同样弱,除了它们保持
<a href="http://www.mjmwired.net/kernel/Documentation/memory-barriers.txt#305">data dependency ordering</a>.它
意味两个相依赖的<code>load</code>(load A, load B&lt;-A)被保证顺序<code>load B&lt;-A</code>总能在
<code>load A</code>之后.(A data dependency barrier is a partial ordering on interdependent loads only; it is not required to have any effect on stores, independent loads or overlapping loads.)</p>

<h3 id="section-2">强内存模型</h3>

<p>弱和强内存模型区别<a href="http://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5903">存
在分歧</a>.<a href="http://preshing.com/20120930/weak-vs-strong-memory-models/">Preshing</a>
总结的定义是:</p>

<p><blockquote><p>一个强硬件内存模型是在这样的硬件上每条机器指令隐性的保证acquire and release<br/>semantics的执行.因此,当一个CPU核进行了一串写操作,每个其他的CPU核看到这<br/>些值的改变顺序与其顺序一致.</p></blockquote></p>

<p>所以也就是保证了四种内存乱序
(<a href="http://g.oswego.edu/dl/jmm/cookbook.html">LoadLoad, StoreStore, LoadStore and StoreLoad</a>)
中的3种,除了不保证StoreLoad的顺序.基于以上的定义,x86/64系列处理器基本
就是强顺序的.之后
<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/#memory-ordering-at-processor-time">Memory ordering at processor time</a>
可以看到StoreLoad在X86/64的乱序实验.</p>

<h3 id="section-3">顺序一致</h3>

<p>在顺序一致
(<a href="http://en.wikipedia.org/wiki/Sequential_consistency">Sequential consistency</a>)
的内存模型中,没有内存乱序存在.</p>

<p>如今,很难找到一个现代多核设备保证在硬件层Sequential consistency.也就早
期的386没有强大到能在运行时进行任何内存的乱序.</p>

<p>当用上层语言编程时,Sequential consistency成为一个重要的软件内存模
型.Java5和之后版本,用<code>volatile</code>声明共享变量.在C+11中,可以使用默认的顺
序约束<code>memory_order_seq_cst</code>在做原子操作时.当使用这些术语后,编译器会限
制编译乱序和插入特定CPU的指令来指定合适的memory barrier类型.</p>

<h2 id="memory-ordering-at-compile-time">Memory ordering at compile time</h2>
<p>看如下代码:</p>

<p><code>c test.c
int A, B;
void test() {
  A = B + 1;
  B = 0;
}
</code></p>

<p>不打开编译器的优化,把它编译成汇编,我们可以看到,<code>B</code>的赋值在<code>A</code>的后面,和
原程序的顺序一样.</p>

<p>``` sh
$ gcc -S -masm=intel test.c</p>

<pre><code>mov	eax, DWORD PTR B
add	eax, 1
mov	DWORD PTR A, eax
mov	DWORD PTR B, 0 ```
</code></pre>

<p>用<code>O2</code>打开优化:</p>

<p>``` sh
$ gcc -S -O2  -masm=intel test.c</p>

<pre><code>mov	eax, DWORD PTR B
mov	DWORD PTR B, 0
add	eax, 1
mov	DWORD PTR A, eax ```
</code></pre>

<p>这次编译器把<code>B</code>的赋值提到<code>A</code>的前面.为什么它可以这么做呢?内存顺序的中心
没有破坏.这样的改变并不影响单线程程序,单线程程序不能知道这样的区别.</p>

<p>但是当编写lock-free代码时,这样的编译器乱序就会引起问题.看如下例子,一个
共享的标识来表明其他共享数据是否更新:</p>

<p><code>c
int value;
int updated = 0;
void UpdateValue(int x) {
    value = x;
    update = 1;
}
</code></p>

<p>如果编译器把<code>update</code>的赋值提到<code>value</code>赋值的前面.即使在单核处理器系统中,会
有问题:在两个参数赋值的中间这个线程被中断,使得另外的程序通过<code>update</code>判
断以为<code>value</code>的值已经得到更新,实际上却没有.</p>

<h3 id="compiler-barriers">显性的Compiler Barriers</h3>
<p>一种方法是用一个特殊的被称为Compiler Barrier的指令来防止编译器优化的乱
序.以下
<a href="http://en.wikipedia.org/wiki/Memory_ordering#Compiler_memory_barrier"><code>asm volative</code></a>
是GCC中的方法.</p>

<p><code>c test_barrier.c
int A, B;
void test() {
  A = B + 1;
  asm volatile("" ::: "memory");
  B = 0;
}
</code></p>

<p>经过这样的修改,打开优化,<code>B</code>的存储将保持在要求的顺序上.</p>

<p>``` sh
$ gcc -S -O2  -masm=intel test.c</p>

<pre><code>mov	eax, DWORD PTR B
add	eax, 1
mov	DWORD PTR A, eax
mov	DWORD PTR B, 0 ```
</code></pre>

<h3 id="compiler-barriers-1">隐性的Compiler Barriers</h3>
<p>在C++11中原子库中,每个不是relaxed的原子操作同时是一个compiler barrier.</p>

<p><code>c++
int value;
std::atomic&lt;int&gt; updated(0);
void UpdateValue(int x) {
    value = x;
    // reordering is prevented here
    update.store(1, std::memory_order_release);
}
</code></p>

<p>每一个拥有compiler barrier的函数本身也是一个compiler barrier,即使它是
inline的.</p>

<p><code>c++
int a;
int b;
void DoSomething() {
    a = 1;
    UpdateValue(1);
    b = a + 1;
}
</code></p>

<p>进一步推知,大多数被调用的函数是一个compiler barrier.无论它们是否包含
memory barrier.排除inline函数,被声明为<a href="http://lwn.net/Articles/285332/"><code>pure attribution</code></a>
或当
<a href="http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0474c/CHDHIEGF.html">link-time code generation</a>
使用时.因为编译器在编译时,并不知道<code>UpdateValue</code>的运行是否依赖于<code>a</code>或会
改变<code>a</code>的值从而影响<code>b</code>,所以编译器不会乱序它们之间的顺序.</p>

<p>可以看到,有许多隐藏的规则禁止编译指令的乱序,也防止了编译器多进一步的代
码优化,所以在某些场景
<a href="https://www.kernel.org/doc/Documentation/volatile-considered-harmful.txt">Why the “volatile” type class should not be used</a>,
来让编译器进一步优化.</p>

<h3 id="section-4">无缘由的存储</h3>

<p>有隐形的Compiler Barriers,同样GCC编译器也有无缘由的存储.来自<a href="https://gcc.gnu.org/ml/gcc/2007-10/msg00266.html">这里的实例</a>:</p>

<p>``` c
extern int v;</p>

<pre><code>void
f(int set_v)
{
  if (set_v)
    v = 1;
}
</code></pre>

<p>```</p>

<p>在i686,GCC 3.3.4–4.3.0用<code>O1</code>编译得到:</p>

<p><code>sh
            pushl   %ebp
            movl    %esp, %ebp
            cmpl    $0, 8(%ebp)
            movl    $1, %eax
            cmove   v, %eax        ; load (maybe)
            movl    %eax, v        ; store (always)
            popl    %ebp
            ret
</code></p>

<p>在单线程中,没有问题,但多线程中调用<code>f(0)</code>仅仅只是读取v的值,但中断后回去
覆盖其他线程修改的值.引起
<a href="http://www.devx.com/cplus/Article/42725">data rate</a>.在新的C++11标准中
明确禁止了这样的行为,看<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3337.pdf">最近C+11标准进行的draft</a>§1.10.22节:</p>

<p><blockquote><p>Compiler transformations that introduce assignments to a potentially shared memory location that would not be modified by the abstract machine are generally precluded by this standard.</p></blockquote></p>

<h2 id="memory-ordering-at-processor-time">Memory ordering at processor time</h2>

<p>看一个简单的CPU乱序的简单例子,即使在强内存模型的X86/64也能看到.有两个
整数<code>X</code>和<code>Y</code>初始是0,另外两个变量r1和r2读取它们的值,两个线程并行运行,执
行如下的机器代码:</p>

<p><img class="center" src="/images/blog/2014/multithreading/ordering-example.png" width="370" height="100" title="‘ordering-example’" ></p>

<p>每个线程存储1到一个共享变量,然后把对方变量读取到一个变量或一个寄存器中.无
论哪个线程先写1到内存,另外个线程读回那个值,意味着最后r1=1或r2=1或两者
都是.但是X86/64是强内存模型,它还是允许<em>乱序</em>机器指令.特别,每个线程允许
延迟存储到读回之后.以致最后r1和r2能同时等于0–违反直觉的一个结果.因为
指令可能如下顺序执行:</p>

<p><img class="center" src="/images/blog/2014/multithreading/reordering-example.png" width="180" height="100" title="‘reordering-example’" ></p>

<h2 id="more">More</h2>

<ol>
  <li><a href="http://www.cl.cam.ac.uk/~pes20/weakmemory/">University of Cambridge整理的文档和论文</a></li>
  <li><a href="http://lwn.net/Articles/470681/">Paul McKenney概括他们做的一些工作和工具</a></li>
  <li><a href="http://www.amazon.com/gp/product/0123973376/ref=as_li_ss_tl?ie=UTF8&amp;tag=preshonprogr-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0123973376">The Art of Multiprocessor Programming</a></li>
  <li><a href="http://www.amazon.com/C-Concurrency-Action-Practical-Multithreading/dp/1933988770/ref=pd_sim_b_2?ie=UTF8&amp;refRID=1QTX99XZAM6HKVG7X0G2">C++ Concurrency in Action: Practical Multithreading</a></li>
</ol>

<h2 id="summarization">Summarization</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Double-Checked Locking Works In C++11]]></title>
    <link href="http://dreamrunner.org/blog/2014/06/22/double-checked-locking-works-in-c-plus-plus-11/"/>
    <updated>2014-06-22T14:07:01+08:00</updated>
    <id>http://dreamrunner.org/blog/2014/06/22/double-checked-locking-works-in-c-plus-plus-11</id>
    <content type="html"><![CDATA[<p>在
<a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">浅谈设计模式六: 单例模式(Singleton)</a>
中提到double-checked locking pattern(DCLP)来实现Singleton设计模式，但是
在C++11之前，没有安全方法在可移植的C++中去实现它．具体原因可见
<a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">单例模式(Singleton)</a>
或Scott Meyers和Andrei Alexandrescu发布的原文
<a href="http://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf">“C++ and the Perils of Double-Checked Locking”</a>
．</p>

<p>C++11引入了新的内存模型和线程库，使得能在C++中实现可移植的DCLP．本文说
明如何实现它．</p>

<!-- more -->

<h2 id="double-checked-locking">什么是Double-Checked Locking</h2>
<p>在
<a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">单例模式(Singleton)</a>
很好的介绍什么是DCLP,这里稍作回顾.</p>

<p>线程安全的方式实现Signleton模式如下:</p>

<p><code>c++ singleton.cc
Singleton* Singleton::instance() {
  Lock lock;    // acquire lock (params omitted for simplicity)
  if(pInstance == NULL) {
    pInstance = new Singleton();
  }
  return pInstance;
  }  // release lock (via Lock destructor)
</code></p>

<p>每次获取 Singleton 都要获取一个锁，但是实际上，我们只有当初始化 pInstance 时才需要一个锁。也就是只发生在第一次调用 instance 时。如果在一个程序运行时， instance 被调用了n次，我们只需要锁在第一次调用时。当我们知道那n-1次锁是没必要的.</p>

<p>DCLP的关键点是发现，大多数 instance 的调用将看到 pInstance 是非空的，因此根本没必要去尝试初始化它。因此，DCLP判断 pInstance 是否为空在尝试获取锁前。只有当判断成功（ pInstance 还没有被初始化）才去获取锁，然后之后这个判断在此进行一次确保 pInstance 是仍然空的。（所以名字叫双重检查锁）。第二个检查是有必要的，因为从上可以看到，另外的线程可能碰巧初始化了 pInstance 在 pInstance 被第一次判断和获取锁之间。</p>

<p><code>c++ singleton-dclp.cc
Singleton* Singleton::instance() {
  Singleton *tmp = pInstance;
  ...  // need memory barrier
  if(tmp == 0) { // 1st test
  Lock lock;
  tmp = pInstance;
  if(tmp == 0) { // 2nd test
    tmp  = new Singleton;
  ...  // need memory barrier
    pInstance = tmp;
  }
  }
return pInstance;
}
</code></p>

<p><a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">单例模式(Singleton)</a>
说明了各种不安全实现的缺陷,主要原因是1) 编译器的乱序编译 和2) CPU的乱
序执行指令.所以安全的实现依靠memory barrier,防止它们的乱序,使得在多线
程中得到同步,C++11之前没有可移植的C/C++函数,但现在,C++11有了.</p>

<h2 id="c11acqurerelease-fence">使用C++11的Acqure和Release Fence</h2>
<p>使用Acqure和Release Fence来实现它,并且保证对实例<code>pInstance</code>进行原子操
作,把它定义为<code>atomic</code>类型,并用<code>memory_order_relaxed</code>操作.(Relaxed
ordering: there are no synchronization or ordering constraints, only
atomicity is required of this operation.)如下实现代码.</p>

<p>``` c++
std::atomic&lt;Singleton *&gt; Singleton::m_pInstance;
std::mutex Singleton::m_mutex;</p>

<p>Singleton* Singleton::instance() {
  Singleton *tmp = m_pInstance.load(std::memory_order_relaxed);
  std::atomic_thread_fence(std::memory_order_acquire);
  if(tmp == nullptr) {
    std::lock_guard<std::mutex> lock(m_mutex);
    tmp = m_pInstance.load(std::memory_order_relaxed);
    if(tmp == nullptr) {
      tmp  = new Singleton;
      std::atomic_thread_fence(std::memory_order_release);
      m_pInstance.store(tmp, std::memory_order_relaxed);
    }
  }
  return m_pInstance;
}
```</std::mutex></p>

<p>在多核系统中,这整个代码也是稳健的,因为memory fences在多个线程间建立了
同步的关系.<code>Singleton::m_pInstance</code>作为guard variable,singleton变
量自身成为payload.</p>

<p>如果没有这层同步关系的话,就不能保证第一个线程的所有写操作(这里就是
singleton实力的创建)被第二个线程读取到,即使<code>m_pInstance</code>已经被第二个线
程能看到.</p>

<h2 id="c11">使用C++11的底层的内存顺序约束</h2>
<p>在C++11中也可以在单元操作时附加底层的内存顺序约束来达到同样的目的.一个
write-release能同步于一个read-release.</p>

<ol>
  <li>
    <p><code>memory_order_acquire</code>: A load operation with this memory order performs the acquire operation on the affected memory location: prior writes made to other memory locations by the thread that did the release become visible in this thread.</p>
  </li>
  <li>
    <p><code>memory_order_release</code>: A store operation with this memory order performs the release operation: prior writes to other memory locations become visible to the threads that do a consume or an acquire on the same location.</p>
  </li>
</ol>

<p>``` c++
std::atomic&lt;Singleton *&gt; Singleton::m_pInstance;
std::mutex Singleton::m_mutex;</p>

<p>Singleton* Singleton::instance() {
  Singleton *tmp = m_pInstance.load(std::memory_order_acquire);
  if(tmp == nullptr) {
    std::lock_guard<std::mutex> lock(m_mutex);
    tmp = m_pInstance.load(std::memory_order_relaxed);
    if(tmp == nullptr) {
      tmp  = new Singleton;
      m_pInstance.store(tmp, std::memory_order_release);
    }
  }
  return m_pInstance;
}
```</std::mutex></p>

<p>从深层分析来看,这种形式的免锁机制的同步比上面单独memory fences来的约束
更小.这种形式的操作只意味在这个操作周围防止内存乱序,而memory fences意
味着在一块区域内防止内存乱序.更多细节参考preshing的
<a href="http://preshing.com/20131125/acquire-and-release-fences-dont-work-the-way-youd-expect/">Acquire and Release Fences Don’t Work the Way You’d Expect</a>
的分析.
## 使用C++11的Sequentially-consistent ordering
C++11还提供了其他的方法来写lock-free的代码.当在atomic操作函数中忽略
<code>std::memory_order</code>参数项,那么默认值是<code>std::memory_order_seq_cst</code>,使得
所有原子参数成为
<a href="http://en.wikipedia.org/wiki/Sequential_consistency">sequentically consistent(SC)</a>
原子.通过SC原子性,整个算法保证sequentically consistent只要没有<a href="http://www.devx.com/cplus/Article/42725">data races</a>.</p>

<p>``` c++
std::atomic&lt;Singleton *&gt; Singleton::m_pInstance;
std::mutex Singleton::m_mutex;</p>

<p>Singleton* Singleton::instance() {
  Singleton *tmp = m_pInstance.load();
  std::atomic_thread_fence(std::memory_order_acquire);
  if(tmp == nullptr) {
    std::lock_guard<std::mutex> lock(m_mutex);
    tmp = m_pInstance.load(std::memory_order_relaxed);
    if(tmp == nullptr) {
      tmp  = new Singleton;
      std::atomic_thread_fence(std::memory_order_release);
      m_pInstance.store(tmp);
    }
  }
  return m_pInstance;
}
```</std::mutex></p>

<p>SC的原子性可能更容易理解.权衡点就是它产生的机器代码没有之前做法的高效.比
如如下是Gcc 4.8.2 intle X64对上面代码产生的机器代码,通过<code>g++ -O2 -std=c++11 -S</code>.
<img src="/images/blog/2014/multithreading/sc.png" title="sc’" ></p>

<p>因为使用了SC原子性,对<code>m_pInstance</code>的存储实现使用了<code>mfence</code>指令,起到一
个在X64上的full memory fence.这是个更严格的指令想对于DCLP在X64上的实际
需求.一个普通的<code>mov</code>足以胜任.但也无关紧要,因为<code>mfence</code>指令也仅仅执行一
次而已,就在创建singleton的实例的代码路径上.</p>

<h2 id="more">More</h2>
<p>使用<a href="http://preshing.com">Preshing</a>的小型可移植的lock-free库,在没有C++11
的支持下,使用它的<a href="http://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/#using-mintomic-fences">Mintomic Fences实现DCLP</a>.</p>

<p>更多关于C++11的multithreading库的详解见之后的文章.</p>
]]></content>
  </entry>
  
</feed>
