<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: C++ | (learn&think)]]></title>
  <link href="http://dreamrunner.org/tags/c-/atom.xml" rel="self"/>
  <link href="http://dreamrunner.org/"/>
  <updated>2014-06-29T11:39:03+08:00</updated>
  <id>http://dreamrunner.org/</id>
  <author>
    <name><![CDATA[DreamRunner]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[浅谈Memory Reordering]]></title>
    <link href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/"/>
    <updated>2014-06-28T22:55:22+08:00</updated>
    <id>http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering</id>
    <content type="html"><![CDATA[<h2 id="memory-ordering">Memory ordering</h2>
<p>在我们编写的C/C++代码和它被在CPU上运行,按照一些规则,代码的内存交互会被
乱序.内存乱序同时由编译器(编译时候)和处理器(运行时)造成,都为了使代码运
行的更快.</p>

<p><img src="/images/blog/2014/multithreading/memory_model.png" title="‘memory_ordering’" ></p>

<p>被编译开发者和处理器制造商遵循的中心内存排序准则是:
<blockquote><p>不能改变单线程程序的行为.</p></blockquote></p>

<p>因为这条规则,在写单线程代码时内存乱序被普遍忽略.即使在多线程程序中,它
也被时常忽略,因为有mutexes,semaphores等来防止它们调用中的内存乱序.仅当
lock-free技术被使用时,内存在不受任何互斥保护下被多个线程共享,内存乱序
的影响能被看到.</p>

<p>下面先比较Weak和Strong的内存模型,然后分两部分,实际内存乱序如何在编译和运行时发生,并如何防止它们.</p>

<!-- more -->

<h2 id="weak-vs-strong-memory-models">Weak VS strong Memory Models</h2>
<p><a href="http://preshing.com/about">Jeff Preshing</a>在
<a href="http://preshing.com/20120930/weak-vs-strong-memory-models/">Weak vs. Strong Memory Models</a>
中很好的总结了从Weak到Strong的类型:</p>

<table>
  <thead>
    <tr>
      <th>非常弱</th>
      <th>数据依赖性的弱</th>
      <th>强制</th>
      <th>顺序一致</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>DEC Alpha</td>
      <td>ARM</td>
      <td>X86/64</td>
      <td>dual 386</td>
    </tr>
    <tr>
      <td>C/C++11 low-level atomics</td>
      <td>PowerPC</td>
      <td>SPARC TSO</td>
      <td>Java volatile/C/C++11 atomics</td>
    </tr>
  </tbody>
</table>

<h3 id="section">弱内存模型</h3>

<p>在最弱的内存模型中,可能经历所有四种内存乱序
(<a href="http://g.oswego.edu/dl/jmm/cookbook.html">LoadLoad, StoreStore, LoadStore and StoreLoad</a>).任
何load或store的操作能与任何的其他的load或store操作乱序,只要它不改变一
个独立进程的行为.实际中,这样的乱序由于编译器引起的指令乱序或处理器本身
处理指令的乱序.</p>

<p>当处理器是弱硬件内存模式,通常称它为weakly-ordered或weak ordering.或说
它有relaxed memory model. <strong>DEC Alpha</strong> 是
<a href="http://www.mjmwired.net/kernel/Documentation/memory-barriers.txt#2277">最具代表</a>
的弱排序的处理器.</p>

<p>C/C++的底层原子操作也呈现弱内存模型,无论代码的平台是如x86/64的强序处理
器.下面章节
<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/#memory-ordering-at-compile-time">Memory ordering at compile time</a>
会演示其弱内存模型,并说明如何强制内存顺
序来保护编译器乱序.</p>

<h3 id="section-1">数据依赖性的弱</h3>

<p>ARM和PowerPC系列的处理器内存模型和Alpha同样弱,除了它们保持
<a href="http://www.mjmwired.net/kernel/Documentation/memory-barriers.txt#305">data dependency ordering</a>.它
意味两个相依赖的<code>load</code>(load A, load B&lt;-A)被保证顺序<code>load B&lt;-A</code>总能在
<code>load A</code>之后.(A data dependency barrier is a partial ordering on interdependent loads only; it is not required to have any effect on stores, independent loads or overlapping loads.)</p>

<h3 id="section-2">强内存模型</h3>

<p>弱和强内存模型区别<a href="http://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5903">存
在分歧</a>.<a href="http://preshing.com/20120930/weak-vs-strong-memory-models/">Preshing</a>
总结的定义是:</p>

<p><blockquote><p>一个强硬件内存模型是在这样的硬件上每条机器指令隐性的保证acquire and release<br/>semantics的执行.因此,当一个CPU核进行了一串写操作,每个其他的CPU核看到这<br/>些值的改变顺序与其顺序一致.</p></blockquote></p>

<p>所以也就是保证了四种内存乱序
(<a href="http://g.oswego.edu/dl/jmm/cookbook.html">LoadLoad, StoreStore, LoadStore and StoreLoad</a>)
中的3种,除了不保证StoreLoad的顺序.基于以上的定义,x86/64系列处理器基本
就是强顺序的.之后
<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/#memory-ordering-at-processor-time">Memory ordering at processor time</a>
可以看到StoreLoad在X86/64的乱序实验.</p>

<h3 id="section-3">顺序一致</h3>

<p>在顺序一致
(<a href="http://en.wikipedia.org/wiki/Sequential_consistency">Sequential consistency</a>)
的内存模型中,没有内存乱序存在.</p>

<p>如今,很难找到一个现代多核设备保证在硬件层Sequential consistency.也就早
期的386没有强大到能在运行时进行任何内存的乱序.</p>

<p>当用上层语言编程时,Sequential consistency成为一个重要的软件内存模
型.Java5和之后版本,用<code>volatile</code>声明共享变量.在C+11中,可以使用默认的顺
序约束<code>memory_order_seq_cst</code>在做原子操作时.当使用这些术语后,编译器会限
制编译乱序和插入特定CPU的指令来指定合适的memory barrier类型.</p>

<h2 id="memory-ordering-at-compile-time">Memory ordering at compile time</h2>
<p>看如下代码:</p>

<p><code>c test.c
int A, B;
void test() {
  A = B + 1;
  B = 0;
}
</code></p>

<p>不打开编译器的优化,把它编译成汇编,我们可以看到,<code>B</code>的赋值在<code>A</code>的后面,和
原程序的顺序一样.</p>

<p>``` sh
$ gcc -S -masm=intel test.c</p>

<pre><code>mov	eax, DWORD PTR B
add	eax, 1
mov	DWORD PTR A, eax
mov	DWORD PTR B, 0 ```
</code></pre>

<p>用<code>O2</code>打开优化:</p>

<p>``` sh
$ gcc -S -O2  -masm=intel test.c</p>

<pre><code>mov	eax, DWORD PTR B
mov	DWORD PTR B, 0
add	eax, 1
mov	DWORD PTR A, eax ```
</code></pre>

<p>这次编译器把<code>B</code>的赋值提到<code>A</code>的前面.为什么它可以这么做呢?内存顺序的中心
没有破坏.这样的改变并不影响单线程程序,单线程程序不能知道这样的区别.</p>

<p>但是当编写lock-free代码时,这样的编译器乱序就会引起问题.看如下例子,一个
共享的标识来表明其他共享数据是否更新:</p>

<p><code>c
int value;
int updated = 0;
void UpdateValue(int x) {
    value = x;
    update = 1;
}
</code></p>

<p>如果编译器把<code>update</code>的赋值提到<code>value</code>赋值的前面.即使在单核处理器系统中,会
有问题:在两个参数赋值的中间这个线程被中断,使得另外的程序通过<code>update</code>判
断以为<code>value</code>的值已经得到更新,实际上却没有.</p>

<h3 id="compiler-barriers">显性的Compiler Barriers</h3>
<p>一种方法是用一个特殊的被称为Compiler Barrier的指令来防止编译器优化的乱
序.以下
<a href="http://en.wikipedia.org/wiki/Memory_ordering#Compiler_memory_barrier"><code>asm volative</code></a>
是GCC中的方法.</p>

<p><code>c test_barrier.c
int A, B;
void test() {
  A = B + 1;
  asm volatile("" ::: "memory");
  B = 0;
}
</code></p>

<p>经过这样的修改,打开优化,<code>B</code>的存储将保持在要求的顺序上.</p>

<p>``` sh
$ gcc -S -O2  -masm=intel test.c</p>

<pre><code>mov	eax, DWORD PTR B
add	eax, 1
mov	DWORD PTR A, eax
mov	DWORD PTR B, 0 ```
</code></pre>

<h3 id="compiler-barriers-1">隐性的Compiler Barriers</h3>
<p>在C++11中原子库中,每个不是relaxed的原子操作同时是一个compiler barrier.</p>

<p><code>c++
int value;
std::atomic&lt;int&gt; updated(0);
void UpdateValue(int x) {
    value = x;
    // reordering is prevented here
    update.store(1, std::memory_order_release);
}
</code></p>

<p>每一个拥有compiler barrier的函数本身也是一个compiler barrier,即使它是
inline的.</p>

<p><code>c++
int a;
int b;
void DoSomething() {
    a = 1;
    UpdateValue(1);
    b = a + 1;
}
</code></p>

<p>进一步推知,大多数被调用的函数是一个compiler barrier.无论它们是否包含
memory barrier.排除inline函数,被声明为<a href="http://lwn.net/Articles/285332/"><code>pure attribution</code></a>
或当
<a href="http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0474c/CHDHIEGF.html">link-time code generation</a>
使用时.因为编译器在编译时,并不知道<code>UpdateValue</code>的运行是否依赖于<code>a</code>或会
改变<code>a</code>的值从而影响<code>b</code>,所以编译器不会乱序它们之间的顺序.</p>

<p>可以看到,有许多隐藏的规则禁止编译指令的乱序,也防止了编译器多进一步的代
码优化,所以在某些场景
<a href="https://www.kernel.org/doc/Documentation/volatile-considered-harmful.txt">Why the “volatile” type class should not be used</a>,
来让编译器进一步优化.</p>

<h3 id="section-4">无缘由的存储</h3>

<p>有隐形的Compiler Barriers,同样GCC编译器也有无缘由的存储.来自<a href="https://gcc.gnu.org/ml/gcc/2007-10/msg00266.html">这里的实例</a>:</p>

<p>``` c
extern int v;</p>

<pre><code>void
f(int set_v)
{
  if (set_v)
    v = 1;
}
</code></pre>

<p>```</p>

<p>在i686,GCC 3.3.4–4.3.0用<code>O1</code>编译得到:</p>

<p><code>sh
            pushl   %ebp
            movl    %esp, %ebp
            cmpl    $0, 8(%ebp)
            movl    $1, %eax
            cmove   v, %eax        ; load (maybe)
            movl    %eax, v        ; store (always)
            popl    %ebp
            ret
</code></p>

<p>在单线程中,没有问题,但多线程中调用<code>f(0)</code>仅仅只是读取v的值,但中断后回去
覆盖其他线程修改的值.引起
<a href="http://www.devx.com/cplus/Article/42725">data rate</a>.在新的C++11标准中
明确禁止了这样的行为,看<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3337.pdf">最近C+11标准进行的draft</a>§1.10.22节:</p>

<p><blockquote><p>Compiler transformations that introduce assignments to a potentially shared memory location that would not be modified by the abstract machine are generally precluded by this standard.</p></blockquote></p>

<h2 id="memory-ordering-at-processor-time">Memory ordering at processor time</h2>

<p>看一个简单的CPU乱序的简单例子,即使在强内存模型的X86/64也能看到.有两个
整数<code>X</code>和<code>Y</code>初始是0,另外两个变量r1和r2读取它们的值,两个线程并行运行,执
行如下的机器代码:</p>

<p><img class="center" src="/images/blog/2014/multithreading/ordering-example.png" width="370" height="100" title="‘ordering-example’" ></p>

<p>每个线程存储1到一个共享变量,然后把对方变量读取到一个变量或一个寄存器中.无
论哪个线程先写1到内存,另外个线程读回那个值,意味着最后r1=1或r2=1或两者
都是.但是X86/64是强内存模型,它还是允许<strong>乱序</strong>机器指令.特别,每个线程允许
延迟存储到读回之后.以致最后r1和r2能同时等于0–违反直觉的一个结果.因为
指令可能如下顺序执行:</p>

<p><img class="center" src="/images/blog/2014/multithreading/reordering-example.png" width="190" height="100" title="‘reordering-example’" ></p>

<p>写一个实例程序,实际看一下CPU的确乱序了指令.源码可以
<a href="https://github.com/shishougang/blog_multithreading/tree/master/memory_reordering">Github下载</a>.两
个读写的线程代码如下:</p>

<p>``` c++
sem_t begin_sem1;
sem_t begin_sem2;
sem_t end_sem;</p>

<p>int X, Y;
int r1, r2;</p>

<p>void *ThreadFunc1(void *param) {
  MersenneTwister random(1);
  for (;;) {
    sem_wait(&amp;begin_sem1);
    // random delay
    while (random.Integer() % 8 != 0) {
    }
    X = 1;
    asm volatile(“” ::: “memory”);  // prevent compiler ordering
    r1 = Y;
    sem_post(&amp;end_sem);
  }
  return NULL;
}</p>

<p>void *ThreadFunc2(void *param) {
  MersenneTwister random(2);
  for (;;) {
    sem_wait(&amp;begin_sem2);
    // random delay
    while (random.Integer() % 8 != 0) {
    }
    Y = 1;
    asm volatile(“” ::: “memory”);  // prevent compiler ordering
    r2 = X;
    sem_post(&amp;end_sem);
  }
  return NULL;
}
```</p>

<p>随机的延迟被插入在存储的开始处,为了交错线程的开始时间,以来达到重叠两个线程
的指令的目的.随机延迟使用线程安全的<code>MersenneTwister</code>类.汇编代码<code>asm
volatile("" ::: "memory");</code>如上节所述只是用来
<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/#memory-ordering-at-compile-time">防止编译器的乱序</a>,
因为这里是要看CPU的乱序,排除编译器的乱序影响.</p>

<p>主线程如下,利用
<a href="http://pubs.opengroup.org/onlinepubs/7908799/xsh/sem_init.html">POSIX的semaphore</a>
同步它与两个子线程的同步.先让两个子线程等待,直到主线程初始化<code>X=0</code>和
<code>Y=0</code>.然后主线程等待,直到两个子线程完成操作,然后主线程检查<code>r1</code>和<code>r2</code>的
值.所以semaphore防止线程见的不同步引起的内存乱序,主线程代码如下:</p>

<p>``` c++
int main(int argc, char *argv[]) {
  sem_init(&amp;begin_sem1, 0, 0);
  sem_init(&amp;begin_sem2, 0, 0);
  sem_init(&amp;end_sem, 0, 0);</p>

<p>pthread_t thread[2];
  pthread_create(&amp;thread[0], NULL, ThreadFunc1, NULL);
  pthread_create(&amp;thread[1], NULL, ThreadFunc2, NULL);</p>

<p>int detected = 0;
  for (int i = 1; ; ++i) {
    X = 0;
    Y = 0;
    sem_post(&amp;begin_sem1);
    sem_post(&amp;begin_sem2);
    sem_wait(&amp;end_sem);
    sem_wait(&amp;end_sem);
    if (r1 == 0 &amp;&amp; r2 == 0) {
      detected++;
      printf(“%d reorders detected after %d iterations\n”, detected, i);
    }
  }
  return 0;
}
```</p>

<p>在Intel i5-2435M X64的ubuntu下运行一下程序:</p>

<p><code>sh
1 reorders detected after 2181 iterations
2 reorders detected after 4575 iterations
3 reorders detected after 7689 iterations
4 reorders detected after 22215 iterations
5 reorders detected after 60023 iterations
6 reorders detected after 60499 iterations
7 reorders detected after 61639 iterations
8 reorders detected after 62243 iterations
9 reorders detected after 67998 iterations
10 reorders detected after 68098 iterations
11 reorders detected after 71179 iterations
12 reorders detected after 71668 iterations
13 reorders detected after 72417 iterations
14 reorders detected after 73970 iterations
15 reorders detected after 78227 iterations
16 reorders detected after 81897 iterations
17 reorders detected after 82722 iterations
18 reorders detected after 85377 iterations
...
</code></p>

<p>差不多每<strong>4000</strong>次的迭代才发现一次CPU内存乱序.所以多线程的bug是多么难
发现.那么如何消除这些乱序.至少有如下两种方法:</p>

<ol>
  <li>让两个子线程在同一个CPU核下运行.(没有可移植性方法,如下是linux平台的).</li>
  <li>使用CPU的memory barrier防止它的乱序.</li>
</ol>

<h3 id="lock-to-one-processor">Lock to one processor</h3>
<p>让两个子线程在同一个CPU核下运行,代码如下:</p>

<p><code>c++
  cpu_set_t cpus;
  CPU_ZERO(&amp;cpus);
  CPU_SER(0, &amp;cpus);
  pthread_setaffinity_np(thread[0], sizeof(cpu_set_t), &amp;cpus);
  pthread_setaffinity_np(thread[1], sizeof(cpu_set_t), &amp;cpus);
</code></p>

<h3 id="place-a-memory-barrier">Place a memory barrier</h3>

<p>防止一个Store在Load之后的乱序,需要一个StoreLoad的barrier.这里使用
<code>mfence</code>的一个全部memory barrier,防止任何类型的内存乱序.代码如下:</p>

<p><code>c++
void *ThreadFunc1(void *param) {
  MersenneTwister random(1);
  for (;;) {
    sem_wait(&amp;begin_sem1);
    // random delay
    while (random.Integer() % 8 != 0) {
    }
    X = 1;
    asm volatile("mfence" ::: "memory");  // prevent CPU ordering
    r1 = Y;
    sem_post(&amp;end_sem);
  }
  return NULL;
  }
</code></p>

<h2 id="more">More</h2>

<ol>
  <li><a href="http://www.cl.cam.ac.uk/~pes20/weakmemory/">University of Cambridge整理的文档和论文</a></li>
  <li><a href="http://lwn.net/Articles/470681/">Paul McKenney概括他们做的一些工作和工具</a></li>
  <li><a href="http://www.amazon.com/gp/product/0123973376/ref=as_li_ss_tl?ie=UTF8&amp;tag=preshonprogr-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0123973376">The Art of Multiprocessor Programming</a></li>
  <li><a href="http://www.amazon.com/C-Concurrency-Action-Practical-Multithreading/dp/1933988770/ref=pd_sim_b_2?ie=UTF8&amp;refRID=1QTX99XZAM6HKVG7X0G2">C++ Concurrency in Action: Practical Multithreading</a></li>
  <li><a href="https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.2011.01.02a.pdf">Is Parallel Programming Hard, And, If So, What Can You Do About It?</a></li>
</ol>

<h2 id="summarization">Summarization</h2>
<ol>
  <li>有两种内存乱序存在:编译器乱序和CPU乱序.</li>
  <li>如何防止编译器乱序.</li>
  <li>如何防止CPU乱序.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[High Resolution Time]]></title>
    <link href="http://dreamrunner.org/blog/2014/06/24/high-resolution-time/"/>
    <updated>2014-06-24T20:19:36+08:00</updated>
    <id>http://dreamrunner.org/blog/2014/06/24/high-resolution-time</id>
    <content type="html"><![CDATA[<p>在不同的平台有繁多的Time API，如何选用精准的高精度Time函数来做
performance benchmarking呢？</p>

<h2 id="wall-clock-time-vs-cpu-time">Wall-clock time VS CPU time</h2>
<p>先理解一些时间的概念。明白不同时间API测量的是什么时间。</p>

<p><a href="http://en.wikipedia.org/wiki/Wall-clock_time">Wall-clock time</a>,顾名思
义，墙上的钟，代表一个任务从开始到完成所经历的时间。它包含3部分：CPU的
时间，I/O的时间和通信延迟的时间。但wall-clock很少是正确的时钟来使用，
因为它随着时区，和daylightsaving改变，或与NTP同步。而这些特性没有一个
是有益的，如果你用它来调度任务或做performance benchmarking。它仅仅如名
字所言，墙上的一个时钟。</p>

<p><a href="http://en.wikipedia.org/wiki/CPU_time">CPU time</a>仅仅统计一个任务从开
始到完成在CPU上所花的时间。CPU time主要包括User time（在user space所花
时间）和System time（在kernel space所花时间）。</p>

<p>以并行程序为例，CPU time就是所有CPU在这个程序所花的时间总和，
Wall-clock time在这种情况可能时间相对短，它只统计任务开始到结束所花时
间。</p>

<!-- more -->

<h2 id="apif1">不同时钟API对比<sup id="fnref:f1"><a href="#fn:f1" rel="footnote">1</a></sup></h2>
<p>对于不同的时钟API,主要分析如下特性：</p>

<ol>
  <li>API测试的是什么时间？（real, user, system，CPU or wall-clock)</li>
  <li>API的精度？(s, ms, µs, or faster?)</li>
  <li>多久时间这个时钟数字会返转？或有什么策略避免它？</li>
  <li>时钟是monotonic的，还是它会随着系统时间改变（比如NTP，time zone，
daylight saving time, by the user, etc)?</li>
</ol>

<p>Linux和OS X的主要时钟API：</p>

<ul>
  <li><a href="http://linux.die.net/man/2/time">time()</a>返回系统的wall-clock，精度
到秒。</li>
  <li><a href="http://linux.die.net/man/3/clock">clock()</a>返回user和systime总共的时
间.现在标准要求<code>CLOCKS_PER_SEC</code>是<code>1000000</code>,使精度最多达到
1µs.<code>clock_t</code>类型平台相关(The range and precision of times
representable in clock_t and time_t are implementation-defined.) 它
wrap around一旦达到最大值.(通常是32位的类型,那么~2^32 ticks后,还是比
较长的时间.)</li>
  <li><a href="http://linux.die.net/man/3/clock_gettime">clock_gettime(CLOCK_MONOTONIC,..)</a>
提供纳秒级的精确度并且是单调的.它的秒和纳秒是分开存储的,所以,任何的
wrap around将很多年才发生一次.它是个不错的时钟,但OS X平台上没有.</li>
  <li><a href="http://linux.die.net/man/2/getrusage">getrusage</a>返回独立的user和
system时间,并且不会wrap around.精确达到1 µs,</li>
  <li><a href="http://linux.die.net/man/2/gettimeofday">gettimeofday</a>返回一个
wall-clock时间并达到µs精度.但是精度不能保证,因为<a href="http://www.lehman.cuny.edu/cgi-bin/man-cgi?gettimeofday+3">依赖于硬件</a>.</li>
  <li><a href="https://developer.apple.com/library/mac/qa/qa1398/_index.html">mach_absolute_time()</a>
是OS X平台的高精度(ns)计时的一个选择.ns以64位unsigned integer存储,实
际使用wrap around不是大问题,移植性是问题.</li>
</ul>

<p>Window的高精度时钟：</p>

<p><a href="http://msdn.microsoft.com/en-us/library/ms644905(VS.85).aspx">QueryPerformanceFrequency()</a>
和
<a href="http://msdn.microsoft.com/en-us/library/ms644904(v=VS.85).aspx">QueryPerformanceCounter()</a>.
QueryPerformanceFrequency() 返回计数的频率,QueryPerformanceCounter()返
回当前计数值.和Linux中CLOCK_MONOTONIC一样,它是一个稳定并单调递增计数器,精
准达到纳秒级,并且不会wrap around.</p>

<p>更多参考:</p>

<ul>
  <li><a href="https://blog.habets.se/2010/09/gettimeofday-should-never-be-used-to-measure-time">gettimeofday() should never be used to measure time</a></li>
  <li><a href="http://tdistler.com/2010/06/27/high-performance-timing-on-linux-windows">High-performance Timing on Linux / Windows</a></li>
</ul>

<h2 id="high-resolution-time">不同平台High Resolution Time</h2>

<h3 id="linux">Linux</h3>
<p>使用
<a href="http://linux.die.net/man/3/clock_gettime">clock_gettime(CLOCK_MONOTONIC,..)</a>
作为High Resolution Time,编译需加上参数<code>-lrt</code>,实例代码如下:</p>

<p>``` c clock_gettime.c
#include <time.h>
#include <stdio.h /></time.h></p>

<p>void GetMonotonicTime(struct timespec *ts) {
  clock_gettime(CLOCK_MONOTONIC, ts);
}</p>

<p>double GetElapsedTime(struct timespec *before, struct timespec *after) {
  double delta_s = after-&gt;tv_sec - before-&gt;tv_sec;
  double delta_ns = after-&gt;tv_nsec - before-&gt;tv_nsec;
  return delta_s * 1e9 + delta_ns;
}</p>

<p>int main(int argc, char *argv[]) {
  struct timespec before, after;
  GetMonotonicTime(&amp;before);
  double sum = 0.0;
  unsigned int i;
  for (i = 1; i &lt; 100; ++i) {
    sum += 1.0 / i;
  }
  GetMonotonicTime(&amp;after);
  printf(“the elapsed time=%e ns\n”, GetElapsedTime(&amp;before, &amp;after));
  return 0;
}
```</p>

<p>除了<code>clock_gettime()</code>高精度时钟外,还有相对应的高精度的睡眠函数
<a href="http://pubs.opengroup.org/onlinepubs/000095399/functions/clock_nanosleep.html">clock_nanosleep</a>,
实例代码如下:</p>

<p>``` c clock_nanosleep.c
#include <time.h /></p>

<p>int main(int argc, char *argv[])
{
  struct timespec sleep_time;
  sleep_time.tv_sec = 0;
  sleep_time.tv_nsec = 100;
  clock_nanosleep(CLOCK_REALTIME, 0, &amp;sleep_time, NULL);
  return 0;
}
```</p>

<h3 id="os-x">OS X</h3>

<h3 id="clockgettime">使用<code>clock_get_time</code></h3>
<p>``` c clock_get_time.c
#include <time.h>
#include <stdio.h>
#include &lt;mach/clock.h&gt;
#include &lt;mach/mach.h&gt;</stdio.h></time.h></p>

<p>void GetMonotonicTime(struct timespec *ts) {
  clock_serv_t cclock;
  mach_timespec_t mts;
  host_get_clock_service(mach_host_self(), SYSTEM_CLOCK, &amp;cclock);
  clock_get_time(cclock, &amp;mts);
  mach_port_deallocate(mach_task_self(), cclock);
  ts-&gt;tv_sec = mts.tv_sec;
  ts-&gt;tv_nsec = mts.tv_nsec;
}</p>

<p>double GetElapsedTime(struct timespec *before, struct timespec *after) {
  double delta_s = after-&gt;tv_sec - before-&gt;tv_sec;
  double delta_ns = after-&gt;tv_nsec - before-&gt;tv_nsec;
  return delta_s * 1e9 + delta_ns;
}</p>

<p>int main(int argc, char *argv[]) {
  struct timespec before, after;
  GetMonotonicTime(&amp;before);
  double sum = 0.0;
  unsigned int i;
  for (i = 1; i &lt; 100; ++i) {
    sum += 1.0 / i;
  }
  GetMonotonicTime(&amp;after);
  printf(“the elapsed time=%e ns\n”, GetElapsedTime(&amp;before, &amp;after));
  return 0;
}
```</p>

<h3 id="machabsolutetime">使用<code>mach_absolute_time</code></h3>
<p><code>c mach_absolute_time.c
int main(int argc, char *argv[]) {
    uint64_t        start;
    uint64_t        end;
    uint64_t        elapsed;
    Nanoseconds     elapsedNano;
    start = mach_absolute_time();
    double sum = 0.0;
    unsigned int i;
    for (i = 1; i &lt; 100; ++i) {
        sum += 1.0 / i;
    }
    end = mach_absolute_time();
    elapsed = end - start;
    // Convert to nanoseconds
    elapsedNano = AbsoluteToNanoseconds( *(AbsoluteTime *) &amp;elapsed );
}
</code></p>

<h3 id="windows">Windows</h3>
<p>``` c++ query_performance.cc
#include <iostream>
#include <windows.h> 
using namespace std;</windows.h></iostream></p>

<p>int main()
{
    LARGE_INTEGER frequency;
    LARGE_INTEGER start, end;
    double elapsedTime;</p>

<pre><code>// get ticks per second
QueryPerformanceFrequency(&amp;frequency);

QueryPerformanceCounter(&amp;start);

//do someting
double sum = 0.0;
unsigned int i;
for (i = 1; i &lt; 100; ++i) {
    sum += 1.0 / i;
}

QueryPerformanceCounter(&amp;end);

// compute and print the elapsed time in millisec
elapsedTime = (end.QuadPart - start.QuadPart) * 1000.0 / frequency.QuadPart;
cout &lt;&lt; elapsedTime &lt;&lt; " ms.\n";
return 0; } ```
</code></pre>

<div class="footnotes">
  <ol>
    <li id="fn:f1">
      <p>http://stackoverflow.com/questions/12392278/measure-time-in-linux-getrusage-vs-clock-gettime-vs-clock-vs-gettimeofday<a href="#fnref:f1" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Double-Checked Locking Works In C++11]]></title>
    <link href="http://dreamrunner.org/blog/2014/06/22/double-checked-locking-works-in-c-plus-plus-11/"/>
    <updated>2014-06-22T14:07:01+08:00</updated>
    <id>http://dreamrunner.org/blog/2014/06/22/double-checked-locking-works-in-c-plus-plus-11</id>
    <content type="html"><![CDATA[<p>在
<a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">浅谈设计模式六: 单例模式(Singleton)</a>
中提到double-checked locking pattern(DCLP)来实现Singleton设计模式，但是
在C++11之前，没有安全方法在可移植的C++中去实现它．具体原因可见
<a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">单例模式(Singleton)</a>
或Scott Meyers和Andrei Alexandrescu发布的原文
<a href="http://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf">“C++ and the Perils of Double-Checked Locking”</a>
．</p>

<p>C++11引入了新的内存模型和线程库，使得能在C++中实现可移植的DCLP．本文说
明如何实现它．</p>

<!-- more -->

<h2 id="double-checked-locking">什么是Double-Checked Locking</h2>
<p>在
<a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">单例模式(Singleton)</a>
很好的介绍什么是DCLP,这里稍作回顾.</p>

<p>线程安全的方式实现Signleton模式如下:</p>

<p><code>c++ singleton.cc
Singleton* Singleton::instance() {
  Lock lock;    // acquire lock (params omitted for simplicity)
  if(pInstance == NULL) {
    pInstance = new Singleton();
  }
  return pInstance;
  }  // release lock (via Lock destructor)
</code></p>

<p>每次获取 Singleton 都要获取一个锁，但是实际上，我们只有当初始化 pInstance 时才需要一个锁。也就是只发生在第一次调用 instance 时。如果在一个程序运行时， instance 被调用了n次，我们只需要锁在第一次调用时。当我们知道那n-1次锁是没必要的.</p>

<p>DCLP的关键点是发现，大多数 instance 的调用将看到 pInstance 是非空的，因此根本没必要去尝试初始化它。因此，DCLP判断 pInstance 是否为空在尝试获取锁前。只有当判断成功（ pInstance 还没有被初始化）才去获取锁，然后之后这个判断在此进行一次确保 pInstance 是仍然空的。（所以名字叫双重检查锁）。第二个检查是有必要的，因为从上可以看到，另外的线程可能碰巧初始化了 pInstance 在 pInstance 被第一次判断和获取锁之间。</p>

<p><code>c++ singleton-dclp.cc
Singleton* Singleton::instance() {
  Singleton *tmp = pInstance;
  ...  // need memory barrier
  if(tmp == 0) { // 1st test
  Lock lock;
  tmp = pInstance;
  if(tmp == 0) { // 2nd test
    tmp  = new Singleton;
  ...  // need memory barrier
    pInstance = tmp;
  }
  }
return pInstance;
}
</code></p>

<p><a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">单例模式(Singleton)</a>
说明了各种不安全实现的缺陷,主要原因是1) 编译器的乱序编译 和2) CPU的乱
序执行指令.所以安全的实现依靠memory barrier,防止它们的乱序,使得在多线
程中得到同步,C++11之前没有可移植的C/C++函数,但现在,C++11有了.</p>

<h2 id="c11acqurerelease-fence">使用C++11的Acqure和Release Fence</h2>
<p>使用Acqure和Release Fence来实现它,并且保证对实例<code>pInstance</code>进行原子操
作,把它定义为<code>atomic</code>类型,并用<code>memory_order_relaxed</code>操作.(Relaxed
ordering: there are no synchronization or ordering constraints, only
atomicity is required of this operation.)如下实现代码.</p>

<p>``` c++
std::atomic&lt;Singleton *&gt; Singleton::m_pInstance;
std::mutex Singleton::m_mutex;</p>

<p>Singleton* Singleton::instance() {
  Singleton *tmp = m_pInstance.load(std::memory_order_relaxed);
  std::atomic_thread_fence(std::memory_order_acquire);
  if(tmp == nullptr) {
    std::lock_guard<std::mutex> lock(m_mutex);
    tmp = m_pInstance.load(std::memory_order_relaxed);
    if(tmp == nullptr) {
      tmp  = new Singleton;
      std::atomic_thread_fence(std::memory_order_release);
      m_pInstance.store(tmp, std::memory_order_relaxed);
    }
  }
  return m_pInstance;
}
```</std::mutex></p>

<p>在多核系统中,这整个代码也是稳健的,因为memory fences在多个线程间建立了
同步的关系.<code>Singleton::m_pInstance</code>作为guard variable,singleton变
量自身成为payload.</p>

<p>如果没有这层同步关系的话,就不能保证第一个线程的所有写操作(这里就是
singleton实力的创建)被第二个线程读取到,即使<code>m_pInstance</code>已经被第二个线
程能看到.</p>

<h2 id="c11">使用C++11的底层的内存顺序约束</h2>
<p>在C++11中也可以在单元操作时附加底层的内存顺序约束来达到同样的目的.一个
write-release能同步于一个read-release.</p>

<ol>
  <li>
    <p><code>memory_order_acquire</code>: A load operation with this memory order performs the acquire operation on the affected memory location: prior writes made to other memory locations by the thread that did the release become visible in this thread.</p>
  </li>
  <li>
    <p><code>memory_order_release</code>: A store operation with this memory order performs the release operation: prior writes to other memory locations become visible to the threads that do a consume or an acquire on the same location.</p>
  </li>
</ol>

<p>``` c++
std::atomic&lt;Singleton *&gt; Singleton::m_pInstance;
std::mutex Singleton::m_mutex;</p>

<p>Singleton* Singleton::instance() {
  Singleton *tmp = m_pInstance.load(std::memory_order_acquire);
  if(tmp == nullptr) {
    std::lock_guard<std::mutex> lock(m_mutex);
    tmp = m_pInstance.load(std::memory_order_relaxed);
    if(tmp == nullptr) {
      tmp  = new Singleton;
      m_pInstance.store(tmp, std::memory_order_release);
    }
  }
  return m_pInstance;
}
```</std::mutex></p>

<p>从深层分析来看,这种形式的免锁机制的同步比上面单独memory fences来的约束
更小.这种形式的操作只意味在这个操作周围防止内存乱序,而memory fences意
味着在一块区域内防止内存乱序.更多细节参考preshing的
<a href="http://preshing.com/20131125/acquire-and-release-fences-dont-work-the-way-youd-expect/">Acquire and Release Fences Don’t Work the Way You’d Expect</a>
的分析.
## 使用C++11的Sequentially-consistent ordering
C++11还提供了其他的方法来写lock-free的代码.当在atomic操作函数中忽略
<code>std::memory_order</code>参数项,那么默认值是<code>std::memory_order_seq_cst</code>,使得
所有原子参数成为
<a href="http://en.wikipedia.org/wiki/Sequential_consistency">sequentically consistent(SC)</a>
原子.通过SC原子性,整个算法保证sequentically consistent只要没有<a href="http://www.devx.com/cplus/Article/42725">data races</a>.</p>

<p>``` c++
std::atomic&lt;Singleton *&gt; Singleton::m_pInstance;
std::mutex Singleton::m_mutex;</p>

<p>Singleton* Singleton::instance() {
  Singleton *tmp = m_pInstance.load();
  std::atomic_thread_fence(std::memory_order_acquire);
  if(tmp == nullptr) {
    std::lock_guard<std::mutex> lock(m_mutex);
    tmp = m_pInstance.load(std::memory_order_relaxed);
    if(tmp == nullptr) {
      tmp  = new Singleton;
      std::atomic_thread_fence(std::memory_order_release);
      m_pInstance.store(tmp);
    }
  }
  return m_pInstance;
}
```</std::mutex></p>

<p>SC的原子性可能更容易理解.权衡点就是它产生的机器代码没有之前做法的高效.比
如如下是Gcc 4.8.2 intle X64对上面代码产生的机器代码,通过<code>g++ -O2 -std=c++11 -S</code>.
<img src="/images/blog/2014/multithreading/sc.png" title="sc’" ></p>

<p>因为使用了SC原子性,对<code>m_pInstance</code>的存储实现使用了<code>mfence</code>指令,起到一
个在X64上的full memory fence.这是个更严格的指令想对于DCLP在X64上的实际
需求.一个普通的<code>mov</code>足以胜任.但也无关紧要,因为<code>mfence</code>指令也仅仅执行一
次而已,就在创建singleton的实例的代码路径上.</p>

<h2 id="more">More</h2>
<p>使用<a href="http://preshing.com">Preshing</a>的小型可移植的lock-free库,在没有C++11
的支持下,使用它的<a href="http://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/#using-mintomic-fences">Mintomic Fences实现DCLP</a>.</p>

<p>更多关于C++11的multithreading库的详解见之后的文章.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Last Thing D Needs总结]]></title>
    <link href="http://dreamrunner.org/blog/2014/06/01/the-last-thing-d-needszong-jie/"/>
    <updated>2014-06-01T16:24:47+08:00</updated>
    <id>http://dreamrunner.org/blog/2014/06/01/the-last-thing-d-needszong-jie</id>
    <content type="html"><![CDATA[<ul id="markdown-toc">
  <li><a href="#initialization">Initialization</a></li>
  <li><a href="#type-deduction">Type Deduction</a></li>
  <li><a href="#inheritance">Inheritance</a></li>
  <li><a href="#computational-complexity">Computational Complexity</a></li>
  <li><a href="#apis">APIs</a></li>
  <li><a href="#specifications">Specifications</a></li>
  <li><a href="#essential-and-accidental-complexity">Essential and Accidental Complexity</a></li>
</ul>

<p><a href="http://www.amazon.com/gp/product/0321334876?ie=UTF8&amp;tag=aristeia.com-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0321334876">Effective C++</a>
系列的作者<a href="http://www.aristeia.com/">Scott Meyers</a>在Dconf中<a href="http://www.ustream.tv/recorded/47947981">The Last Thing D Needs</a>聊了些C++的
特性，稍微总结一下。</p>

<h2 id="initialization">Initialization</h2>

<p><code>c++ Initialization
int x1;         // unknown, initial(pay for it)
int x2;         // (at global scope) 0, no run time cost
static int x3;  // 0, static initialization
int *px = new int;  // heap memory, unknown, has run time cost
{
    int x4;    // unknown, has run time cost 
}
int a1[100];   // unknown
int a2[100];   // (at global scope) 0
static int a3[100];  // 0
std::vector&lt;int&gt; v(100);  // 0, use run time cost
</code></p>

<!-- more -->

<h2 id="type-deduction">Type Deduction</h2>
<p>``` c++ Type Deduction
const int cx = 0;
auto my_cx1 = cx;          // int, new independent value
decltype(cx) my_cx2 = cx;  // const int, standard said</p>

<p>template<typname t="">
void f1(T param);
f1(cx);                    // T's type, int, same rules with auto</typname></p>

<p>template<typename t="">
void f2(T&amp; param);
f2(cx);                   //T's type, const int, reference a chunk of memory, preserve the const</typename></p>

<p>template<typename t="">
void f3(T&amp;&amp; param);
f3(cx);                  //T's type, const int&amp;, perfect argument forwarding, a special rule</typename></p>

<p>const int cx = 0;
auto lam= [cx] {cx = 10;};       //error!
class UpToTheCompiler {
private:
  ??? cx;                      //const int
  …
};</p>

<p>const int cx = 0;
auto lam= [cx = cx] {cx = 10;};     //error!
class UpToTheCompiler {
private:
  ??? cx;                          //int (but acts like const int)
  …
public:
  void operator() const
  {cx = 0;}
};</p>

<p>const int cx = 0;
auto lam1= [cx = cx] mutable {cx = 10;};     //error!
auto lam2= <a href="">cx = cx</a> mutable {cx = 10;};     //correct
class UpToTheCompiler {
private:
  ??? cx;                          //int (but acts like int)
  …
};
```</p>

<p>For
<div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>const int cx = 0;</span></code></pre></td></tr></table></div></figure></notextile></div>
type deduction for cx yields:</p>

<style>
table,th,td
{
border:1px solid black;
}
</style>

<table border="1" style="width:500px">
<tr>
<th> Context </th>
<th> Type </th>
</tr>

<tr>
<td> auto </td>
<td> int </td>
</tr>

<tr>
<td> decltype </td>
<td>  const int</td>
</tr>

<tr>
<td> template(T parameter)  </td>
<td> int </td>
</tr>

<tr>
<td> template(T&amp; parameter)  </td>
<td> const int </td>
</tr>

<tr>
<td> template(T&amp;&amp; parameter)  </td>
<td> const int&amp; </td>
</tr>

<tr>
<td> lambda (by-value capture) </td>
<td> const int  </td>
</tr>

<tr>
<td> lambda (int capture) </td>
<td>  int</td>
</tr>
</table>

<p>``` c++ Type Deduction
//all do the same thing
int x1 = 0;
int x2(0);
int x3 = {0};
int x4 {0};</p>

<p>auto x1 = 0;  // int
auto x2(0);   // int
auto x3 = {0};// initializer_list<int>
auto x4 {0};  // initializer_list<int /></int></p>

<p>template <typname t="">
void f(T param);
f({0});       // error! "{0}" has no type
```</typname></p>

<h2 id="inheritance">Inheritance</h2>
<p>``` c++ inheritance
class Base {
public:
  void doBaseWork();
};
class Derived : public Base {
public:
  void doDerivedWord() {
    doBaseWord();               //ok
  }
};</p>

<p>template <typename t="">
class Base {
public:
  void doBaseWork();
};
template <typename t="">
class Derived : public Base<t> {
public:
  void doDerivedWord() {
    doBaseWord();               //no compile, later specialized version
  }
};</t></typename></typename></p>

<p>template &lt;&gt;
class Base<int> ();  // no doBasework</int></p>

<p>Derived<int> d;
d.doDerivedWord();  // fail
```</int></p>

<p>In essence, the <strong>One Definition Rule</strong> states that the same entity should have the exact same definition throughout an application, otherwise the effects are undefined.</p>

<p>The fundamental problem is that the code that doesn’t see the specialized version of your class template member function might still compile, is likely to link, and sometimes might even run. This is because in the absence of (a forward declaration of) the explicit specialization, the non-specialized version kicks in, likely implementing a generic functionality that works for your specialized type as well.</p>

<h2 id="computational-complexity">Computational Complexity</h2>
<p>``` c++ computational Complexity
std::vector<int> v;
...
std::sort(v.begin(), v.end());   // O(nlogn)</int></p>

<p>std::list<int> li;
...
std::sort(li.begin(), li.end());  // not compile, list doesnot have random access iterator</int></p>

<p>auto it1 =
std::binary_search(v.begin(), v.end(), 10);  // O(logn)</p>

<p>auto it2 =
std::binary_search(li.begin(), li.end(), 10);  // O(n), officially(number of compares): O(logn)
```</p>

<h2 id="apis">APIs</h2>

<p><code>c++ example
std::set&lt;int&gt; si;
...
si.erase(14);    // eliminate all 14s from si
</code></p>

<ul>
  <li>set             –&gt;  erase</li>
  <li>multiset        –&gt;     erase</li>
  <li>map             –&gt;     erase</li>
  <li>multimap        –&gt;     erase</li>
  <li>unordered_set   –&gt;     erase</li>
  <li>unordered_multiset –&gt;  erase</li>
  <li>unordered_map      –&gt;  erase</li>
  <li>unordered_multimap –&gt;  erase</li>
  <li>list               –&gt;  remove</li>
  <li>forward_list       –&gt;  remove</li>
</ul>

<p>Sorts can be stable or unstable. Which are guaranteed to be stable?
* sort –&gt; not guaranteed
* stable_sort  –&gt; guaranteed
* list::sort –&gt; guaranteed</p>

<h2 id="specifications">Specifications</h2>
<p>Five sequence containers:</p>

<ul>
  <li>array –&gt; No</li>
  <li>deque –&gt; Yes</li>
  <li>forward_list  –&gt; No(fulfill of 1 of 16)</li>
  <li>list  –&gt; Yes</li>
  <li>vector – &gt; Yes</li>
</ul>

<h2 id="essential-and-accidental-complexity">Essential and Accidental Complexity</h2>
<p>Essential Complexity: due to inherent design tensions.</p>

<ul>
  <li>Simplicity and regularity vs expressiveness.</li>
  <li>Abstraction and portability vs efficiency.</li>
  <li>New approaches vs compatibility with legacy systems.</li>
  <li>Expressiveness vs ability to issue good diagnostics.</li>
</ul>

<p><em>Essential Complexity</em></p>

<p><code>c++ Point
struct Point {
  int x, y;
};
</code>
What is the type of Point::x?</p>

<p><code>c++ Point
Point p;
const Point &amp;cp = p;
</code>
What is the type of cp.x?</p>

<p>C++ soluction:</p>

<p><code>c++
decltype(cp.x) = int
decltype((cp.x)) = const int&amp;
</code></p>

<p><code>c++ inheritance
template &lt;typename T&gt;
class Base {
public:
  void doBaseWork();
};
template &lt;typename T&gt;
class Derived : public Base&lt;T&gt; {
public:
  void doDerivedWord() {
    doBaseWrd();               //okay?
  }
};
</code></p>

<p>Assume typo and diagnose now?</p>

<ul>
  <li>Wrong if later specialization offers doBaseWrk.</li>
</ul>

<p>Assume later specialization and defer lookup until instantiation?</p>

<ul>
  <li>If typo, imposes diagnostics for library errors on clients.</li>
</ul>

<p>C++ solution:</p>

<ul>
  <li>Template author has control
    <ul>
      <li>doBaseWrk() -&gt; lookup name when parsing template.</li>
      <li>this-&gt;doBaseWrk() -&gt; lookup name when instantiating template.</li>
    </ul>
  </li>
</ul>

<p><em>Accidental Complexity</em></p>

<ul>
  <li>ints are sometimes initialized to 0.</li>
  <li>By-value lambda capture somtimes retains the constness of what’s captured.</li>
  <li>mutable lambdas must declare a parameter list, but non-mutable lambdas don’t</li>
  <li>Braced initializers (e.g.”{0}”) sometimes have a type.</li>
  <li>Computation complexity guarantees usually meaningful.</li>
  <li>Elimination all container elements with a given value usually means
calling <code>erase</code>.</li>
  <li><code>sort</code> is sometimes stable.</li>
  <li>Container “requirements” are sometimes required.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[设计模式基本原则]]></title>
    <link href="http://dreamrunner.org/blog/2014/05/05/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99/"/>
    <updated>2014-05-05T00:00:00+08:00</updated>
    <id>http://dreamrunner.org/blog/2014/05/05/设计模式基本原则</id>
    <content type="html"><![CDATA[<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> 封装那些改变的</h2>
<div class="outline-text-2" id="text-1">
<p>
识别出应用里改变的方面，然后把它们从不变部分里分离出来封装。这样变化的部分就不会影响到不变的部分。那么，之后代码改变的话，只需要修改封装好的变化部分，不引起无意的修改，并提供更好的扩展灵活性。
</p>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> 面向接口编程，而不是实现</h2>
<div class="outline-text-2" id="text-2">
<ol class="org-ol">
<li>由接口定义要实现的每个行为；
</li>
<li>只要依照接口定义好的编程实现；
</li>
<li>我们只需要知道接口是如何，根本不需要实现的细节而去使用这个接口派生的对象；
</li>
<li>在运行时才赋值具体的实现对象。
</li>
</ol>
</div>
</div>
<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> 使用组合优于继承</h2>
<div class="outline-text-2" id="text-3">
<p>
使用组合创建系统提高灵活性。不单单可以使你把一族的算法封装成它们各自的类，同时让你在运行时可以改变算法行为。
</p>

<p>
而继承，子类直接实现好算法的具体行为，不能在运行时改变算法的行为，同时过多的继承加剧类图的复杂度。
</p>

<!-- more -->
</div>
</div>
<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> 追求交互对象间的松耦合</h2>
<div class="outline-text-2" id="text-4">
<p>
当两个对象松耦合时，它们能交互，但互相了解很少。松耦合让我们建立能适应变化的灵活系统，因为它们最小化对象间的内部依赖。
</p>

<p>
松耦合对象A和B：
</p>
<ol class="org-ol">
<li>A和B只要知道对方的接口，就可以互相调用对方;
</li>
<li>我们可以独立复用A或B;
</li>
<li>改变A或B不会影响对方。
</li>
</ol>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> 类需要对扩展开放，对修改闭合(The Open-Closed Principle)</h2>
<div class="outline-text-2" id="text-5">
<ol class="org-ol">
<li>开放：自由添加任何新的行为来扩展类。
</li>
<li>闭合：现有的代码经过长时间的测试和修正，不允许别人修改现有代码。
</li>
</ol>

<p>
目的是允许类能容易的被扩展新的行为而不用修改现有的代码。为了达到这个目的，模式设计需要能弹性改变并足够灵活来对变化需求的新功能做出反应。
</p>
</div>
</div>
<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6"><span class="section-number-2">6</span> 依赖于抽象类，而不是依赖具体类（The Dependency Inversion Principle)</h2>
<div class="outline-text-2" id="text-6">
<p>
与“面向接口编程，而不是实现“原则类似，然而依赖反转原则对于抽象接口更严格：
</p>

<ol class="org-ol">
<li>高层次的模块不应该依赖于低层次的模块，两者都应该依赖于抽象接口。
</li>
<li>抽象接口不应该依赖于具体实现。而具体实现则应该依赖于抽象接口。
</li>
</ol>
</div>
</div>
<div id="outline-container-sec-7" class="outline-2">
<h2 id="sec-7"><span class="section-number-2">7</span> 得墨忒耳定律(Law of Demeter or Principle of Least Knowledge)</h2>
<div class="outline-text-2" id="text-7">
<p>
得墨忒耳定律是松耦合的一种具体案例:
</p>
<ol class="org-ol">
<li>每个单元对于其他的单元只能拥有有限的知识：只是与当前单元紧密联系的单元；
</li>
<li>每个单元只能和它的朋友交谈：不能和陌生单元交谈；
</li>
<li>只和自己直接的朋友交谈
</li>
</ol>

<p>
这个原理的名称来源于希腊神话中的农业女神，孤独的得墨忒耳。
</p>
</div>
</div>
<div id="outline-container-sec-8" class="outline-2">
<h2 id="sec-8"><span class="section-number-2">8</span> 好莱坞原则(Hollywood Principle)</h2>
<div class="outline-text-2" id="text-8">
<p>
总的概括就是：不要调用我们（高层次模块），我们会调用你（低层次模块）。
</p>

<p>
好莱坞原则提供一种防止依赖腐烂的方法。依赖腐烂发生当高层次模块依赖于低层次模块，低层次模块依赖于高层次模块，高层次模块又依赖于边际模块，边际模块依赖于低层次模块如此。当腐烂发生，没有人能轻易理解这个系统如何设计。
</p>

<p>
遵循好莱坞原则，允许低层次模块连入到系统中，但是由高层次模块决定什么时候它们被需要，和怎么使用它们。而不允许低层次的模块直接去调用一个高层次模块。
</p>
</div>
</div>
<div id="outline-container-sec-9" class="outline-2">
<h2 id="sec-9"><span class="section-number-2">9</span> 单一功能原则（Single Responsibility Principle）</h2>
<div class="outline-text-2" id="text-9">
<p>
单一功能原则（Single responsibility principle）规定每个类都应该有一个单一的功能，并且该功能应该由这个类完全封装起来。
</p>

<p>
也就是一个类或者模块应该有且只有一个改变的原因。一个具体的例子就是，想象有一个用于编辑和打印报表的模块。这样的一个模块存在两个改变的原因。第一，报表的内容可以改变（编辑）。第二，报表的格式可以改变（打印）。这两方面会的改变因为完全不同的起因而发生：一个是本质的修改，一个是表面的修改。单一功能原则认为这两方面的问题事实上是两个分离的功能，因此他们应该分离在不同的类或者模块里。把有不同的改变原因的事物耦合在一起的设计是糟糕的。
</p>

<p>
保持一个类专注于单一功能点上的一个重要的原因是，它会使得类更加的健壮。继续上面的例子，如果有一个对于报表编辑流程的修改，那么将存在极大的危险性，打印功能的代码会因此不工作，假使这两个功能存在于同一个类中的话。
</p>
</div>
</div>
]]></content>
  </entry>
  
</feed>
