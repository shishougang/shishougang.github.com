<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Multithreading | (learn&think)]]></title>
  <link href="http://dreamrunner.org/blog/categories/multithreading/atom.xml" rel="self"/>
  <link href="http://dreamrunner.org/"/>
  <updated>2014-07-01T22:57:37+08:00</updated>
  <id>http://dreamrunner.org/</id>
  <author>
    <name><![CDATA[DreamRunner]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[浅谈Memory Reordering]]></title>
    <link href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/"/>
    <updated>2014-06-28T22:55:22+08:00</updated>
    <id>http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering</id>
    <content type="html"><![CDATA[<h2 id="memory-ordering">Memory ordering</h2>
<p>在我们编写的 C/C++代码和它被在 CPU 上运行,按照一些规则,代码的内存交互会被
乱序.内存乱序同时由编译器(编译时候)和处理器(运行时)造成,都为了使代码运
行的更快.</p>

<p><img src="/images/blog/2014/multithreading/memory_model.png" title="‘memory_ordering’" ></p>

<p>被编译开发者和处理器制造商遵循的中心内存排序准则是:
<blockquote><p>不能改变单线程程序的行为.</p></blockquote></p>

<p>因为这条规则,在写单线程代码时内存乱序被普遍忽略.即使在多线程程序中,它
也被时常忽略,因为有 mutexes,semaphores 等来防止它们调用中的内存乱序.仅当
lock-free 技术被使用时,内存在不受任何互斥保护下被多个线程共享,内存乱序
的影响能被看到.</p>

<p>下面先比较 Weak 和 Strong 的内存模型,然后分两部分,实际内存乱序如何在编译和运行时发生,并如何防止它们.</p>

<!-- more -->

<h2 id="weak-vs-strong-memory-models">Weak VS strong Memory Models</h2>
<p><a href="http://preshing.com/about">Jeff Preshing</a> 在
<a href="http://preshing.com/20120930/weak-vs-strong-memory-models/">Weak vs. Strong Memory Models</a>
中很好的总结了从 Weak 到 Strong 的类型:</p>

<table>
  <thead>
    <tr>
      <th>非常弱</th>
      <th>数据依赖性的弱</th>
      <th>强制</th>
      <th>顺序一致</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>DEC Alpha</td>
      <td>ARM</td>
      <td>X86/64</td>
      <td>dual 386</td>
    </tr>
    <tr>
      <td>C/C++11 low-level atomics</td>
      <td>PowerPC</td>
      <td>SPARC TSO</td>
      <td>Java volatile/C/C++11 atomics</td>
    </tr>
  </tbody>
</table>

<h3 id="section">弱内存模型</h3>

<p>在最弱的内存模型中,可能经历所有四种内存乱序
(<a href="http://g.oswego.edu/dl/jmm/cookbook.html">LoadLoad, StoreStore, LoadStore and StoreLoad</a>).任
何 load 或 store 的操作能与任何的其他的 load 或 store 操作乱序,只要它不改变一
个独立进程的行为.实际中,这样的乱序由于编译器引起的指令乱序或处理器本身
处理指令的乱序.</p>

<p>当处理器是弱硬件内存模式,通常称它为 weakly-ordered 或 weak ordering.或说
它有 relaxed memory model. <strong>DEC Alpha</strong> 是
<a href="http://www.mjmwired.net/kernel/Documentation/memory-barriers.txt#2277">最具代表</a>
的弱排序的处理器.</p>

<p>C/C++的底层原子操作也呈现弱内存模型,无论代码的平台是如 x86/64 的强序处理
器.下面章节
<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/#memory-ordering-at-compile-time">Memory ordering at compile time</a>
会演示其弱内存模型,并说明如何强制内存顺
序来保护编译器乱序.</p>

<h3 id="section-1">数据依赖性的弱</h3>

<p>ARM 和 PowerPC 系列的处理器内存模型和 Alpha 同样弱,除了它们保持
<a href="http://www.mjmwired.net/kernel/Documentation/memory-barriers.txt#305">data dependency ordering</a>.它
意味两个相依赖的<code>load</code>(load A, load B&lt;-A)被保证顺序<code>load B&lt;-A</code>总能在
<code>load A</code>之后.(A data dependency barrier is a partial ordering on interdependent loads only; it is not required to have any effect on stores, independent loads or overlapping loads.)</p>

<h3 id="section-2">强内存模型</h3>

<p>弱和强内存模型区别<a href="http://herbsutter.com/2012/08/02/strong-and-weak-hardware-memory-models/#comment-5903">存
在分歧</a>.<a href="http://preshing.com/20120930/weak-vs-strong-memory-models/">Preshing</a>
总结的定义是:</p>

<p><blockquote><p>一个强硬件内存模型是在这样的硬件上每条机器指令隐性的保证 acquire and release<br/>semantics 的执行.因此,当一个 CPU 核进行了一串写操作,每个其他的 CPU 核看到这<br/>些值的改变顺序与其顺序一致.</p></blockquote></p>

<p>所以也就是保证了四种内存乱序
(<a href="http://g.oswego.edu/dl/jmm/cookbook.html">LoadLoad, StoreStore, LoadStore and StoreLoad</a>)
中的 3 种,除了不保证 StoreLoad 的顺序.基于以上的定义,x86/64 系列处理器基本
就是强顺序的.之后
<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/#memory-ordering-at-processor-time">Memory ordering at processor time</a>
可以看到 StoreLoad 在 X86/64 的乱序实验.</p>

<h3 id="section-3">顺序一致</h3>

<p>在顺序一致
(<a href="http://en.wikipedia.org/wiki/Sequential_consistency">Sequential consistency</a>)
的内存模型中,没有内存乱序存在.</p>

<p>如今,很难找到一个现代多核设备保证在硬件层 Sequential consistency.也就早
期的 386 没有强大到能在运行时进行任何内存的乱序.</p>

<p>当用上层语言编程时,Sequential consistency 成为一个重要的软件内存模
型.Java5 和之后版本,用<code>volatile</code>声明共享变量.在 C+11 中,可以使用默认的顺
序约束<code>memory_order_seq_cst</code>在做原子操作时.当使用这些术语后,编译器会限
制编译乱序和插入特定 CPU 的指令来指定合适的 memory barrier 类型.</p>

<h2 id="memory-ordering-at-compile-time">Memory ordering at compile time</h2>
<p>看如下代码:</p>

<p><code>c test.c
int A, B;
void test() {
  A = B + 1;
  B = 0;
}
</code></p>

<p>不打开编译器的优化,把它编译成汇编,我们可以看到,<code>B</code>的赋值在<code>A</code>的后面,和
原程序的顺序一样.</p>

<p>``` sh
$ gcc -S -masm=intel test.c</p>

<pre><code>mov	eax, DWORD PTR B
add	eax, 1
mov	DWORD PTR A, eax
mov	DWORD PTR B, 0 ```
</code></pre>

<p>用<code>O2</code>打开优化:</p>

<p>``` sh
$ gcc -S -O2  -masm=intel test.c</p>

<pre><code>mov	eax, DWORD PTR B
mov	DWORD PTR B, 0
add	eax, 1
mov	DWORD PTR A, eax ```
</code></pre>

<p>这次编译器把<code>B</code>的赋值提到<code>A</code>的前面.为什么它可以这么做呢?内存顺序的中心
没有破坏.这样的改变并不影响单线程程序,单线程程序不能知道这样的区别.</p>

<p>但是当编写 lock-free 代码时,这样的编译器乱序就会引起问题.看如下例子,一个
共享的标识来表明其他共享数据是否更新:</p>

<p><code>c
int value;
int updated = 0;
void UpdateValue(int x) {
    value = x;
    update = 1;
}
</code></p>

<p>如果编译器把<code>update</code>的赋值提到<code>value</code>赋值的前面.即使在单核处理器系统中,会
有问题:在两个参数赋值的中间这个线程被中断,使得另外的程序通过<code>update</code>判
断以为<code>value</code>的值已经得到更新,实际上却没有.</p>

<h3 id="compiler-barriers">显性的 Compiler Barriers</h3>
<p>一种方法是用一个特殊的被称为 Compiler Barrier 的指令来防止编译器优化的乱
序.以下
<a href="http://en.wikipedia.org/wiki/Memory_ordering#Compiler_memory_barrier"><code>asm volative</code></a>
是 GCC 中的方法.</p>

<p><code>c test_barrier.c
int A, B;
void test() {
  A = B + 1;
  asm volatile("" ::: "memory");
  B = 0;
}
</code></p>

<p>经过这样的修改,打开优化,<code>B</code>的存储将保持在要求的顺序上.</p>

<p>``` sh
$ gcc -S -O2  -masm=intel test.c</p>

<pre><code>mov	eax, DWORD PTR B
add	eax, 1
mov	DWORD PTR A, eax
mov	DWORD PTR B, 0 ```
</code></pre>

<h3 id="compiler-barriers-1">隐性的 Compiler Barriers</h3>
<p>在 C++11 中原子库中,每个不是 relaxed 的原子操作同时是一个 compiler barrier.</p>

<p><code>c++
int value;
std::atomic&lt;int&gt; updated(0);
void UpdateValue(int x) {
    value = x;
    // reordering is prevented here
    update.store(1, std::memory_order_release);
}
</code></p>

<p>每一个拥有 compiler barrier 的函数本身也是一个 compiler barrier,即使它是
inline 的.</p>

<p><code>c++
int a;
int b;
void DoSomething() {
    a = 1;
    UpdateValue(1);
    b = a + 1;
}
</code></p>

<p>进一步推知,大多数被调用的函数是一个 compiler barrier.无论它们是否包含
memory barrier.排除 inline 函数,被声明为<a href="http://lwn.net/Articles/285332/"><code>pure attribution</code></a>
或当
<a href="http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0474c/CHDHIEGF.html">link-time code generation</a>
使用时.因为编译器在编译时,并不知道<code>UpdateValue</code>的运行是否依赖于<code>a</code>或会
改变<code>a</code>的值从而影响<code>b</code>,所以编译器不会乱序它们之间的顺序.</p>

<p>可以看到,有许多隐藏的规则禁止编译指令的乱序,也防止了编译器多进一步的代
码优化,所以在某些场景
<a href="https://www.kernel.org/doc/Documentation/volatile-considered-harmful.txt">Why the “volatile” type class should not be used</a>,
来让编译器进一步优化.</p>

<h3 id="section-4">无缘由的存储</h3>

<p>有隐形的 Compiler Barriers,同样 GCC 编译器也有无缘由的存储.来自<a href="https://gcc.gnu.org/ml/gcc/2007-10/msg00266.html">这里的实例</a>:</p>

<p>``` c
extern int v;</p>

<pre><code>void
f(int set_v)
{
  if (set_v)
    v = 1;
}
</code></pre>

<p>```</p>

<p>在 i686,GCC 3.3.4–4.3.0 用<code>O1</code>编译得到:</p>

<p><code>sh
            pushl   %ebp
            movl    %esp, %ebp
            cmpl    $0, 8(%ebp)
            movl    $1, %eax
            cmove   v, %eax        ; load (maybe)
            movl    %eax, v        ; store (always)
            popl    %ebp
            ret
</code></p>

<p>在单线程中,没有问题,但多线程中调用<code>f(0)</code>仅仅只是读取 v 的值,但中断后回去
覆盖其他线程修改的值.引起
<a href="http://www.devx.com/cplus/Article/42725">data rate</a>.在新的 C++11 标准中
明确禁止了这样的行为,看<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3337.pdf">最近 C+11 标准进行的 draft</a>§1.10.22 节:</p>

<p><blockquote><p>Compiler transformations that introduce assignments to a potentially shared memory location that would not be modified by the abstract machine are generally precluded by this standard.</p></blockquote></p>

<h2 id="memory-ordering-at-processor-time">Memory ordering at processor time</h2>

<p>看一个简单的 CPU 乱序的简单例子,即使在强内存模型的 X86/64 也能看到.有两个
整数<code>X</code>和<code>Y</code>初始是 0,另外两个变量 r1 和 r2 读取它们的值,两个线程并行运行,执
行如下的机器代码:</p>

<p><img class="center" src="/images/blog/2014/multithreading/ordering-example.png" width="370" height="100" title="‘ordering-example’" ></p>

<p>每个线程存储 1 到一个共享变量,然后把对方变量读取到一个变量或一个寄存器中.无
论哪个线程先写 1 到内存,另外个线程读回那个值,意味着最后 r1=1 或 r2=1 或两者
都是.但是 X86/64 是强内存模型,它还是允许<strong>乱序</strong>机器指令.特别,每个线程允许
延迟存储到读回之后.以致最后 r1 和 r2 能同时等于 0–违反直觉的一个结果.因为
指令可能如下顺序执行:</p>

<p><img class="center" src="/images/blog/2014/multithreading/reordering-example.png" width="190" height="100" title="‘reordering-example’" ></p>

<p>写一个实例程序,实际看一下 CPU 的确乱序了指令.源码可以
<a href="https://github.com/shishougang/blog_multithreading/tree/master/memory_reordering">Github 下载</a>.两
个读写的线程代码如下:</p>

<p>``` c++
sem_t begin_sem1;
sem_t begin_sem2;
sem_t end_sem;</p>

<p>int X, Y;
int r1, r2;</p>

<p>void *ThreadFunc1(void *param) {
  MersenneTwister random(1);
  for (;;) {
    sem_wait(&amp;begin_sem1);
    // random delay
    while (random.Integer() % 8 != 0) {
    }
    X = 1;
    asm volatile(“” ::: “memory”);  // prevent compiler ordering
    r1 = Y;
    sem_post(&amp;end_sem);
  }
  return NULL;
}</p>

<p>void *ThreadFunc2(void *param) {
  MersenneTwister random(2);
  for (;;) {
    sem_wait(&amp;begin_sem2);
    // random delay
    while (random.Integer() % 8 != 0) {
    }
    Y = 1;
    asm volatile(“” ::: “memory”);  // prevent compiler ordering
    r2 = X;
    sem_post(&amp;end_sem);
  }
  return NULL;
}
```</p>

<p>随机的延迟被插入在存储的开始处,为了交错线程的开始时间,以来达到重叠两个线程
的指令的目的.随机延迟使用线程安全的<code>MersenneTwister</code>类.汇编代码<code>asm
volatile("" ::: "memory");</code>如上节所述只是用来
<a href="http://dreamrunner.org/blog/2014/06/28/qian-tan-memory-reordering/#memory-ordering-at-compile-time">防止编译器的乱序</a>,
因为这里是要看 CPU 的乱序,排除编译器的乱序影响.</p>

<p>主线程如下,利用
<a href="http://pubs.opengroup.org/onlinepubs/7908799/xsh/sem_init.html">POSIX 的 semaphore</a>
同步它与两个子线程的同步.先让两个子线程等待,直到主线程初始化<code>X=0</code>和
<code>Y=0</code>.然后主线程等待,直到两个子线程完成操作,然后主线程检查<code>r1</code>和<code>r2</code>的
值.所以 semaphore 防止线程见的不同步引起的内存乱序,主线程代码如下:</p>

<p>``` c++
int main(int argc, char *argv[]) {
  sem_init(&amp;begin_sem1, 0, 0);
  sem_init(&amp;begin_sem2, 0, 0);
  sem_init(&amp;end_sem, 0, 0);</p>

<p>pthread_t thread[2];
  pthread_create(&amp;thread[0], NULL, ThreadFunc1, NULL);
  pthread_create(&amp;thread[1], NULL, ThreadFunc2, NULL);</p>

<p>int detected = 0;
  for (int i = 1; ; ++i) {
    X = 0;
    Y = 0;
    sem_post(&amp;begin_sem1);
    sem_post(&amp;begin_sem2);
    sem_wait(&amp;end_sem);
    sem_wait(&amp;end_sem);
    if (r1 == 0 &amp;&amp; r2 == 0) {
      detected++;
      printf(“%d reorders detected after %d iterations\n”, detected, i);
    }
  }
  return 0;
}
```</p>

<p>在 Intel i5-2435M X64 的 ubuntu 下运行一下程序:</p>

<p><code>sh
1 reorders detected after 2181 iterations
2 reorders detected after 4575 iterations
3 reorders detected after 7689 iterations
4 reorders detected after 22215 iterations
5 reorders detected after 60023 iterations
6 reorders detected after 60499 iterations
7 reorders detected after 61639 iterations
8 reorders detected after 62243 iterations
9 reorders detected after 67998 iterations
10 reorders detected after 68098 iterations
11 reorders detected after 71179 iterations
12 reorders detected after 71668 iterations
13 reorders detected after 72417 iterations
14 reorders detected after 73970 iterations
15 reorders detected after 78227 iterations
16 reorders detected after 81897 iterations
17 reorders detected after 82722 iterations
18 reorders detected after 85377 iterations
...
</code></p>

<p>差不多每 <strong>4000</strong> 次的迭代才发现一次 CPU 内存乱序.所以多线程的 bug 是多么难
发现.那么如何消除这些乱序.至少有如下两种方法:</p>

<ol>
  <li>让两个子线程在同一个 CPU 核下运行.(没有可移植性方法,如下是 linux 平台的).</li>
  <li>使用 CPU 的 memory barrier 防止它的乱序.</li>
</ol>

<h3 id="lock-to-one-processor">Lock to one processor</h3>
<p>让两个子线程在同一个 CPU 核下运行,代码如下:</p>

<p><code>c++
  cpu_set_t cpus;
  CPU_ZERO(&amp;cpus);
  CPU_SET(0, &amp;cpus);
  pthread_setaffinity_np(thread[0], sizeof(cpu_set_t), &amp;cpus);
  pthread_setaffinity_np(thread[1], sizeof(cpu_set_t), &amp;cpus);
</code></p>

<h3 id="place-a-memory-barrier">Place a memory barrier</h3>

<p>防止一个 Store 在 Load 之后的乱序,需要一个 StoreLoad 的 barrier.这里使用
<code>mfence</code>的一个全部 memory barrier,防止任何类型的内存乱序.代码如下:</p>

<p><code>c++
void *ThreadFunc1(void *param) {
  MersenneTwister random(1);
  for (;;) {
    sem_wait(&amp;begin_sem1);
    // random delay
    while (random.Integer() % 8 != 0) {
    }
    X = 1;
    asm volatile("mfence" ::: "memory");  // prevent CPU ordering
    r1 = Y;
    sem_post(&amp;end_sem);
  }
  return NULL;
  }
</code></p>

<h2 id="more">More</h2>

<ol>
  <li><a href="http://www.cl.cam.ac.uk/~pes20/weakmemory/">University of Cambridge 整理的文档和论文</a></li>
  <li><a href="http://lwn.net/Articles/470681/">Paul McKenney 概括他们做的一些工作和工具</a></li>
  <li><a href="http://www.amazon.com/gp/product/0123973376/ref=as_li_ss_tl?ie=UTF8&amp;tag=preshonprogr-20&amp;linkCode=as2&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0123973376">The Art of Multiprocessor Programming</a></li>
  <li><a href="http://www.amazon.com/C-Concurrency-Action-Practical-Multithreading/dp/1933988770/ref=pd_sim_b_2?ie=UTF8&amp;refRID=1QTX99XZAM6HKVG7X0G2">C++ Concurrency in Action: Practical Multithreading</a></li>
  <li><a href="https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.2011.01.02a.pdf">Is Parallel Programming Hard, And, If So, What Can You Do About It?</a></li>
</ol>

<h2 id="summarization">Summarization</h2>
<ol>
  <li>有两种内存乱序存在:编译器乱序和 CPU 乱序.</li>
  <li>如何防止编译器乱序.</li>
  <li>如何防止 CPU 乱序.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Double-Checked Locking Works in C++11]]></title>
    <link href="http://dreamrunner.org/blog/2014/06/22/double-checked-locking-works-in-c-plus-plus-11/"/>
    <updated>2014-06-22T14:07:01+08:00</updated>
    <id>http://dreamrunner.org/blog/2014/06/22/double-checked-locking-works-in-c-plus-plus-11</id>
    <content type="html"><![CDATA[<p>在
<a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">浅谈设计模式六: 单例模式(Singleton)</a>
中提到 double-checked locking pattern(DCLP)来实现 Singleton 设计模式，但是
在 C++11 之前，没有安全方法在可移植的 C++中去实现它．具体原因可见
<a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">单例模式(Singleton)</a>
或 Scott Meyers 和 Andrei Alexandrescu 发布的原文
<a href="http://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf">“C++ and the Perils of Double-Checked Locking”</a>
．</p>

<p>C++11 引入了新的内存模型和线程库，使得能在 C++中实现可移植的 DCLP．本文说
明如何实现它．</p>

<!-- more -->

<h2 id="double-checked-locking">什么是 Double-Checked Locking</h2>
<p>在
<a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">单例模式(Singleton)</a>
很好的介绍什么是 DCLP,这里稍作回顾.</p>

<p>线程安全的方式实现 Signleton 模式如下:</p>

<p><code>c++ singleton.cc
Singleton* Singleton::instance() {
  Lock lock;    // acquire lock (params omitted for simplicity)
  if(pInstance == NULL) {
    pInstance = new Singleton();
  }
  return pInstance;
  }  // release lock (via Lock destructor)
</code></p>

<p>每次获取 Singleton 都要获取一个锁，但是实际上，我们只有当初始化 pInstance 时才需要一个锁。也就是只发生在第一次调用 instance 时。如果在一个程序运行时， instance 被调用了 n 次，我们只需要锁在第一次调用时。当我们知道那 n-1 次锁是没必要的.</p>

<p>DCLP 的关键点是发现，大多数 instance 的调用将看到 pInstance 是非空的，因此根本没必要去尝试初始化它。因此，DCLP 判断 pInstance 是否为空在尝试获取锁前。只有当判断成功（ pInstance 还没有被初始化）才去获取锁，然后之后这个判断在此进行一次确保 pInstance 是仍然空的。（所以名字叫双重检查锁）。第二个检查是有必要的，因为从上可以看到，另外的线程可能碰巧初始化了 pInstance 在 pInstance 被第一次判断和获取锁之间。</p>

<p><code>c++ singleton-dclp.cc
Singleton* Singleton::instance() {
  Singleton *tmp = pInstance;
  ...  // need memory barrier
  if(tmp == 0) { // 1st test
  Lock lock;
  tmp = pInstance;
  if(tmp == 0) { // 2nd test
    tmp  = new Singleton;
  ...  // need memory barrier
    pInstance = tmp;
  }
  }
return pInstance;
}
</code></p>

<p><a href="http://dreamrunner.org/blog/2014/05/03/%E6%B5%85%E8%B0%88%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F6/">单例模式(Singleton)</a>
说明了各种不安全实现的缺陷,主要原因是 1) 编译器的乱序编译 和 2) CPU 的乱
序执行指令.所以安全的实现依靠 memory barrier,防止它们的乱序,使得在多线
程中得到同步,C++11 之前没有可移植的 C/C++函数,但现在,C++11 有了.</p>

<h2 id="c11--acqure--release-fence">使用 C++11 的 Acqure 和 Release Fence</h2>
<p>使用 Acqure 和 Release Fence 来实现它,并且保证对实例<code>pInstance</code>进行原子操
作,把它定义为<code>atomic</code>类型,并用<code>memory_order_relaxed</code>操作.(Relaxed
ordering: there are no synchronization or ordering constraints, only
atomicity is required of this operation.)如下实现代码.</p>

<p>``` c++
std::atomic&lt;Singleton *&gt; Singleton::m_pInstance;
std::mutex Singleton::m_mutex;</p>

<p>Singleton* Singleton::instance() {
  Singleton *tmp = m_pInstance.load(std::memory_order_relaxed);
  std::atomic_thread_fence(std::memory_order_acquire);
  if(tmp == nullptr) {
    std::lock_guard<std::mutex> lock(m_mutex);
    tmp = m_pInstance.load(std::memory_order_relaxed);
    if(tmp == nullptr) {
      tmp  = new Singleton;
      std::atomic_thread_fence(std::memory_order_release);
      m_pInstance.store(tmp, std::memory_order_relaxed);
    }
  }
  return m_pInstance;
}
```</std::mutex></p>

<p>在多核系统中,这整个代码也是稳健的,因为 memory fences 在多个线程间建立了
同步的关系.<code>Singleton::m_pInstance</code>作为 guard variable,singleton 变
量自身成为 payload.</p>

<p>如果没有这层同步关系的话,就不能保证第一个线程的所有写操作(这里就是
singleton 实力的创建)被第二个线程读取到,即使<code>m_pInstance</code>已经被第二个线
程能看到.</p>

<h2 id="c11-">使用 C++11 的底层的内存顺序约束</h2>
<p>在 C++11 中也可以在单元操作时附加底层的内存顺序约束来达到同样的目的.一个
write-release 能同步于一个 read-release.</p>

<ol>
  <li>
    <p><code>memory_order_acquire</code>: A load operation with this memory order performs the acquire operation on the affected memory location: prior writes made to other memory locations by the thread that did the release become visible in this thread.</p>
  </li>
  <li>
    <p><code>memory_order_release</code>: A store operation with this memory order performs the release operation: prior writes to other memory locations become visible to the threads that do a consume or an acquire on the same location.</p>
  </li>
</ol>

<p>``` c++
std::atomic&lt;Singleton *&gt; Singleton::m_pInstance;
std::mutex Singleton::m_mutex;</p>

<p>Singleton* Singleton::instance() {
  Singleton *tmp = m_pInstance.load(std::memory_order_acquire);
  if(tmp == nullptr) {
    std::lock_guard<std::mutex> lock(m_mutex);
    tmp = m_pInstance.load(std::memory_order_relaxed);
    if(tmp == nullptr) {
      tmp  = new Singleton;
      m_pInstance.store(tmp, std::memory_order_release);
    }
  }
  return m_pInstance;
}
```</std::mutex></p>

<p>从深层分析来看,这种形式的免锁机制的同步比上面单独 memory fences 来的约束
更小.这种形式的操作只意味在这个操作周围防止内存乱序,而 memory fences 意
味着在一块区域内防止内存乱序.更多细节参考 preshing 的
<a href="http://preshing.com/20131125/acquire-and-release-fences-dont-work-the-way-youd-expect/">Acquire and Release Fences Don’t Work the Way You’d Expect</a>
的分析.
## 使用 C++11 的 Sequentially-consistent ordering
C++11 还提供了其他的方法来写 lock-free 的代码.当在 atomic 操作函数中忽略
<code>std::memory_order</code>参数项,那么默认值是<code>std::memory_order_seq_cst</code>,使得
所有原子参数成为
<a href="http://en.wikipedia.org/wiki/Sequential_consistency">sequentically consistent(SC)</a>
原子.通过 SC 原子性,整个算法保证 sequentically consistent 只要没有 <a href="http://www.devx.com/cplus/Article/42725">data races</a>.</p>

<p>``` c++
std::atomic&lt;Singleton *&gt; Singleton::m_pInstance;
std::mutex Singleton::m_mutex;</p>

<p>Singleton* Singleton::instance() {
  Singleton *tmp = m_pInstance.load();
  std::atomic_thread_fence(std::memory_order_acquire);
  if(tmp == nullptr) {
    std::lock_guard<std::mutex> lock(m_mutex);
    tmp = m_pInstance.load(std::memory_order_relaxed);
    if(tmp == nullptr) {
      tmp  = new Singleton;
      std::atomic_thread_fence(std::memory_order_release);
      m_pInstance.store(tmp);
    }
  }
  return m_pInstance;
}
```</std::mutex></p>

<p>SC 的原子性可能更容易理解.权衡点就是它产生的机器代码没有之前做法的高效.比
如如下是 Gcc 4.8.2 intle X64 对上面代码产生的机器代码,通过<code>g++ -O2 -std=c++11 -S</code>.
<img src="/images/blog/2014/multithreading/sc.png" title="sc’" ></p>

<p>因为使用了 SC 原子性,对<code>m_pInstance</code>的存储实现使用了<code>mfence</code>指令,起到一
个在 X64 上的 full memory fence.这是个更严格的指令想对于 DCLP 在 X64 上的实际
需求.一个普通的<code>mov</code>足以胜任.但也无关紧要,因为<code>mfence</code>指令也仅仅执行一
次而已,就在创建 singleton 的实例的代码路径上.</p>

<h2 id="more">More</h2>
<p>使用 <a href="http://preshing.com">Preshing</a> 的小型可移植的 lock-free 库,在没有 C++11
的支持下,使用它的 <a href="http://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/#using-mintomic-fences">Mintomic Fences 实现 DCLP</a>.</p>

<p>更多关于 C++11 的 multithreading 库的详解见之后的文章.</p>
]]></content>
  </entry>
  
</feed>
